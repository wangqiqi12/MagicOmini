import os
import torch
import gradio as gr
import numpy as np
from diffusers.pipelines import FluxPipeline
from PIL import Image, ImageDraw
import cv2
import argparse

from omini.pipeline.flux_omini import Condition, generate, seed_everything

# å…¨å±€å˜é‡
N_POINTS = 1
USE_CPU = False  # æ˜¯å¦ä½¿ç”¨CPUè¿è¡Œ
DEVICE = "cuda"  # é»˜è®¤è®¾å¤‡

pipe = None
edit_confirmed = False  # ç¼–è¾‘ç¡®è®¤çŠ¶æ€
color_confirmed = False  # é¢œè‰²æç¤ºç¡®è®¤çŠ¶æ€
current_edit_data = None  # å½“å‰ç¼–è¾‘æ•°æ®
current_color_data = None  # å½“å‰é¢œè‰²æç¤ºæ•°æ®
last_sketch_hash = None  # ä¸Šæ¬¡ç¼–è¾‘æ•°æ®çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æµ‹å˜åŒ–
last_color_hash = None  # ä¸Šæ¬¡é¢œè‰²æ•°æ®çš„å“ˆå¸Œå€¼
refresh_counter = 0  # å¼ºåˆ¶åˆ·æ–°è®¡æ•°å™¨
local_backup = {}  # æœ¬åœ°çŠ¶æ€å¤‡ä»½ï¼Œé˜²æ­¢ç½‘ç»œä¸­æ–­ä¸¢å¤±çŠ¶æ€
click_timestamps = []  # ç‚¹å‡»æ—¶é—´æˆ³ï¼Œç”¨äºæ£€æµ‹ç½‘ç»œå»¶è¿Ÿ
status_check_counter = 0  # çŠ¶æ€æ£€æŸ¥è®¡æ•°å™¨
last_operation_time = 0  # æœ€åæ“ä½œæ—¶é—´

def initialize_pipeline():
    """åˆå§‹åŒ–pipeline - æ”¯æŒCPU/GPUé€‰æ‹©ï¼Œè¿”å›çŠ¶æ€ä¿¡æ¯"""
    global pipe, USE_CPU, DEVICE
    
    if pipe is not None:
        return True, f"âœ… Pipelineå·²å°±ç»ª (è®¾å¤‡: {DEVICE})"
    
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–pipeline...")
    
    try:
        # æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§
        if USE_CPU:
            DEVICE = "cpu"
            print("âš™ï¸ ä½¿ç”¨CPUæ¨¡å¼")
        else:
            if not torch.cuda.is_available():
                print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
                DEVICE = "cpu"
                USE_CPU = True
            else:
                DEVICE = "cuda"
                print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        
        # NOTE: è¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„
        local_path = "/root/private_data/wangqiqi12/Omini_ckpts/FLUX.1-dev"
        
        print(f"ğŸ“‚ åŠ è½½åŸºç¡€æ¨¡å‹: {local_path}")
        # æ ¹æ®è®¾å¤‡é€‰æ‹©åŠ è½½æ¨¡å‹
        if USE_CPU:
            print("âš™ï¸ ä½¿ç”¨CPUåŠ è½½æ¨¡å‹ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰...")
            pipe = FluxPipeline.from_pretrained(
                local_path,
                torch_dtype=torch.float32,  # CPUä½¿ç”¨float32
                device_map="cpu",
                low_cpu_mem_usage=True,
            )
        else:
            pipe = FluxPipeline.from_pretrained(
                local_path,
                torch_dtype=torch.bfloat16,  # GPUä½¿ç”¨bfloat16
                device_map="cuda",
                low_cpu_mem_usage=True,
            )
        
        # éªŒè¯æ¨¡å‹è®¾å¤‡ä¿¡æ¯
        try:
            if hasattr(pipe, 'device'):
                print(f"ğŸ” Pipelineè®¾å¤‡: {pipe.device}")
            elif hasattr(pipe, 'transformer') and hasattr(pipe.transformer, 'device'):
                print(f"ğŸ” Transformerè®¾å¤‡: {pipe.transformer.device}")
            print(f"ğŸ¯ å½“å‰è¿è¡Œè®¾å¤‡: {DEVICE}")
        except:
            pass
        
        print("ğŸ“¦ åŠ è½½LoRAæƒé‡...")
        # NOTE: è¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…LoRAè·¯å¾„  
        lora_path = "/root/private_data/wangqiqi12/Omini_ckpts/omni_ckpts/color_sketch_1024"
        
        # æ£€æŸ¥LoRAæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        import os
        lora_file = os.path.join(lora_path, "default.safetensors")
        if not os.path.exists(lora_file):
            error_msg = f"âŒ LoRAæ–‡ä»¶ä¸å­˜åœ¨: {lora_file}"
            print(error_msg)
            print("   è¯·æ£€æŸ¥è·¯å¾„æˆ–æƒé‡æ–‡ä»¶å")
            return False, error_msg
        
        pipe.load_lora_weights(
            lora_path,
            weight_name="default.safetensors",
            adapter_name="sketch",
        )
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ä¼˜åŒ–å†…å­˜
        pipe.unet.eval() if hasattr(pipe, 'unet') else None
        pipe.transformer.eval() if hasattr(pipe, 'transformer') else None
        
        # å¯ç”¨å†…å­˜ä¼˜åŒ–ï¼ˆä¸device_mapå…¼å®¹ï¼‰
        try:
            pipe.enable_attention_slicing()
            print("âœ… å·²å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ä»¥èŠ‚çœå†…å­˜")
        except Exception as e:
            print(f"âš ï¸ æ³¨æ„åŠ›åˆ‡ç‰‡ä¸å¯ç”¨: {e}")
        
        # è®¾å¤‡ç‰¹å®šä¼˜åŒ–
        if USE_CPU:
            print("ğŸ’¡ CPUæ¨¡å¼ï¼šæ¨èä½¿ç”¨è¾ƒå°‘çš„æ¨ç†æ­¥æ•°ä»¥åŠ å¿«é€Ÿåº¦")
        else:
            print("ğŸ’¡ ä½¿ç”¨device_mapè‡ªåŠ¨ç®¡ç†GPUå†…å­˜")
        
        print(f"ğŸ‰ Pipelineåˆå§‹åŒ–å®Œæˆ! (è®¾å¤‡: {DEVICE})")
        return True, f"âœ… Pipelineåˆå§‹åŒ–å®Œæˆ! (è®¾å¤‡: {DEVICE})"
        
    except FileNotFoundError as e:
        error_msg = f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {str(e)}"
        print(error_msg)
        return False, error_msg
    except torch.cuda.OutOfMemoryError as e:
        error_msg = f"âŒ GPUå†…å­˜ä¸è¶³: {str(e)}"
        print(error_msg)
        print("ğŸ’¡ å»ºè®®: å°è¯•é‡å¯ç¨‹åºæˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
        return False, error_msg
    except Exception as e:
        error_msg = f"âŒ Pipelineåˆå§‹åŒ–å¤±è´¥: {str(e)}"
        print(error_msg)
        return False, error_msg

def create_masked_image_from_sketch(base_image, sketch_data):
    """ä»baseå›¾åƒå’Œç”¨æˆ·ç¼–è¾‘çš„sketchåˆ›å»ºmaskedå›¾åƒ"""
    if base_image is None:
        return None, "è¯·å…ˆä¸Šä¼ åŸºç¡€å›¾åƒ"
    
    if sketch_data is None:
        return None, "è¯·å…ˆåœ¨å›¾åƒä¸Šç¼–è¾‘maskåŒºåŸŸ"
    
    try:
        # å¤„ç†baseå›¾åƒ
        if isinstance(base_image, np.ndarray):
            base_image = Image.fromarray(base_image.astype(np.uint8))
        base_image = base_image.resize((1024, 1024)).convert('RGB')
        
        # å¤„ç†ç”¨æˆ·ç¼–è¾‘åçš„å›¾åƒæ•°æ®
        edited_image = None
        
        print(f"Debug: sketch_data type: {type(sketch_data)}")
        
        if isinstance(sketch_data, dict):
            print(f"Debug: sketch_data keys: {sketch_data.keys()}")
            # å°è¯•å¸¸è§çš„å­—æ®µå - ä¼˜å…ˆä½¿ç”¨compositeï¼ˆåˆæˆå›¾åƒï¼‰
            possible_keys = ['composite', 'image', 'background', 'layers', 'data']
            for key in possible_keys:
                if key in sketch_data and sketch_data[key] is not None:
                    edited_image = sketch_data[key]
                    print(f"Debug: ä½¿ç”¨å­—æ®µ '{key}'")
                    break
        elif isinstance(sketch_data, np.ndarray):
            edited_image = sketch_data
        elif isinstance(sketch_data, Image.Image):
            edited_image = sketch_data
        else:
            edited_image = sketch_data
        
        if edited_image is None:
            return None, "æ— æ³•ä»ç¼–è¾‘æ•°æ®ä¸­æå–å›¾åƒ"
        
        # ç»Ÿä¸€è½¬æ¢ä¸ºPILå›¾åƒ    
        if isinstance(edited_image, np.ndarray):
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            if edited_image.dtype != np.uint8:
                edited_image = (edited_image * 255).astype(np.uint8) if edited_image.max() <= 1 else edited_image.astype(np.uint8)
            edited_image = Image.fromarray(edited_image)
        elif not isinstance(edited_image, Image.Image):
            return None, f"ä¸æ”¯æŒçš„å›¾åƒæ•°æ®ç±»å‹: {type(edited_image)}"
        
        # è°ƒæ•´å°ºå¯¸å’Œæ ¼å¼
        edited_image = edited_image.resize((1024, 1024)).convert('RGB')
        
        # åˆ›å»ºmaskï¼šæ£€æµ‹ç™½è‰²æ¶‚æŠ¹åŒºåŸŸ
        edited_array = np.array(edited_image)
        base_array = np.array(base_image)
        
        # æ‰¾åˆ°ç”¨æˆ·ç”¨ç™½è‰²ç¬”æ¶‚æŠ¹çš„åŒºåŸŸï¼ˆæ¥è¿‘ç™½è‰²çš„åƒç´ ï¼‰
        # ç™½è‰²æ¶‚æŠ¹åŒºåŸŸï¼šRGBå€¼éƒ½å¾ˆé«˜ï¼ˆæ¥è¿‘255ï¼‰
        white_mask = ((edited_array[:,:,0] > 240) & 
                     (edited_array[:,:,1] > 240) & 
                     (edited_array[:,:,2] > 240))
        
        # åŒæ—¶æ’é™¤åŸå›¾ä¸­æœ¬æ¥å°±æ˜¯ç™½è‰²çš„åŒºåŸŸ
        original_white = ((base_array[:,:,0] > 240) & 
                         (base_array[:,:,1] > 240) & 
                         (base_array[:,:,2] > 240))
        
        # çœŸæ­£çš„maskåŒºåŸŸï¼šç¼–è¾‘åæ˜¯ç™½è‰²ä½†åŸå›¾ä¸æ˜¯ç™½è‰²çš„åŒºåŸŸ
        mask_region = white_mask & ~original_white
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ˜æ˜¾çš„ç™½è‰²æ¶‚æŠ¹ï¼Œåˆ™æ£€æµ‹æ‰€æœ‰æ˜æ˜¾å˜åŒ–çš„åŒºåŸŸ
        if np.sum(mask_region) < 100:  # å¦‚æœmaskåŒºåŸŸå¤ªå°
            # è®¡ç®—åƒç´ å·®å¼‚
            diff = np.abs(edited_array.astype(np.float32) - base_array.astype(np.float32))
            diff_magnitude = np.sum(diff, axis=2)
            # æ‰¾åˆ°å·®å¼‚è¾ƒå¤§çš„åŒºåŸŸï¼ˆç”¨æˆ·ç¼–è¾‘è¿‡çš„åŒºåŸŸï¼‰
            mask_region = diff_magnitude > 30
        
        # åˆ›å»ºæœ€ç»ˆçš„maskedå›¾åƒ
        # ç”¨æˆ·ç¼–è¾‘åçš„å›¾åƒå°±æ˜¯æˆ‘ä»¬è¦çš„æ¡ä»¶å›¾åƒ
        masked_image = edited_image.copy()
        
        # ç»Ÿè®¡maskåŒºåŸŸ
        mask_pixels = np.sum(mask_region)
        total_pixels = mask_region.size
        mask_percentage = (mask_pixels / total_pixels) * 100
        
        status = f"ç¼–è¾‘æ£€æµ‹æˆåŠŸ! MaskåŒºåŸŸ: {mask_pixels} åƒç´  ({mask_percentage:.1f}%)"
        
        return masked_image, status
        
    except Exception as e:
        return None, f"å¤„ç†ç¼–è¾‘å›¾åƒå¤±è´¥: {str(e)}"

def extract_color_hints_from_strokes(stroke_image, original_cond_image, radius=5, n_points=70):
    """ä»é¢œè‰²ç¬”è§¦ä¸­ç›´æ¥æå–çº¯è‰²æ–¹å— - å‚è€ƒcolor_hint_ui.py"""
    if stroke_image is None or original_cond_image is None:
        return None
    
    # ç¡®ä¿stroke_imageæ˜¯numpyæ•°ç»„
    if isinstance(stroke_image, Image.Image):
        stroke_array = np.array(stroke_image)
    else:
        stroke_array = stroke_image
        
    h, w = stroke_array.shape[:2]
    
    # æ£€æµ‹åŸå§‹æ¡ä»¶å›¾ä¸­çš„ç™½è‰²maskåŒºåŸŸ
    if isinstance(original_cond_image, Image.Image):
        original_cond_array = np.array(original_cond_image)
    else:
        original_cond_array = original_cond_image
        
    original_gray = cv2.cvtColor(original_cond_array, cv2.COLOR_RGB2GRAY)
    white_mask_area = original_gray > 240  # ç™½è‰²åŒºåŸŸ

    # å¦‚æœæ¡ä»¶å›¾ä¸­æ²¡æœ‰æ˜æ˜¾çš„ç™½è‰²maskï¼ˆç”¨æˆ·å¯èƒ½æ²¡æœ‰ä¸¥æ ¼ä½¿ç”¨ç™½è‰²é®ç½©ï¼‰ï¼Œ
    # ä¸è¦ç›´æ¥æ”¾å¼ƒï¼›æ”¹ä¸ºå°†æ•´ä¸ªå›¾åƒä½œä¸ºå€™é€‰åŒºåŸŸä»¥ä¾¿æå–é¢œè‰²æç¤ºï¼ˆæ›´å®½æ¾çš„å®¹é”™å¤„ç†ï¼‰ã€‚
    if not np.any(white_mask_area):
        # å®½æ¾å›é€€ï¼šå…è®¸å…¨å›¾ä½œä¸ºmaskåŒºåŸŸï¼Œä½†ä¼šåœ¨åç»­æ­¥éª¤ä¸­ä»ç„¶æ£€æµ‹é¢œè‰²å’Œå·®å¼‚
        white_mask_area = np.ones_like(original_gray, dtype=bool)
    
    # æ£€æŸ¥å›¾åƒå½¢çŠ¶æ˜¯å¦åŒ¹é…
    if stroke_array.shape != original_cond_array.shape:
        return original_cond_image
    
    # è®¡ç®—ç¼–è¾‘å‰åçš„å·®å¼‚ï¼Œæ‰¾åˆ°æ–°æ·»åŠ çš„é¢œè‰²stroke
    diff = np.abs(stroke_array.astype(np.float32) - original_cond_array.astype(np.float32))
    diff_sum = np.sum(diff, axis=2)
    
    # æ£€æµ‹æœ‰æ˜æ˜¾å˜åŒ–çš„åŒºåŸŸ
    significant_change = diff_sum > 30
    
    # æ£€æµ‹stroke_imageä¸­çš„é¢œè‰²ï¼ˆæ’é™¤æç«¯é»‘/ç™½ï¼‰ï¼Œé˜ˆå€¼ç¨å¾®æ”¾å®½ä»¥æ•æ‰æ›´æ·¡çš„é¢œè‰²ç¬”è§¦
    stroke_gray = cv2.cvtColor(stroke_array, cv2.COLOR_RGB2GRAY)
    has_color = (stroke_gray > 20) & (stroke_gray < 245)  # ä¸æ˜¯ææš—ä¹Ÿä¸æ˜¯å‡ ä¹çº¯ç™½
    
    # æ‰¾åˆ°æ—¢åœ¨ç™½è‰²maskåŒºåŸŸã€åˆæœ‰é¢œè‰²ã€åˆæ˜¯æ–°æ·»åŠ çš„åƒç´ 
    valid_color_indices = np.argwhere(significant_change & has_color & white_mask_area)
    
    if len(valid_color_indices) == 0:
        return original_cond_image
    
    # åˆ›å»ºæ–°çš„æ¡ä»¶å›¾ï¼Œä»åŸå›¾å¼€å§‹
    new_cond_array = original_cond_array.copy()
    
    # ä»æœ‰é¢œè‰²çš„åƒç´ ä¸­éšæœºé‡‡æ ·
    n_sample = min(n_points, len(valid_color_indices))
    sampled_indices = valid_color_indices[np.random.choice(
        len(valid_color_indices), size=n_sample, replace=False)]
    
    n_valid = 0
    for y, x in sampled_indices:
        # è¾¹ç•Œæ£€æŸ¥
        if y - radius < 0 or y + radius >= h or x - radius < 0 or x + radius >= w:
            continue
        
        # æ£€æŸ¥è¿™ä¸ªpatchæ˜¯å¦å®Œå…¨åœ¨ç™½è‰²maskå†…
        patch_white_area = white_mask_area[y - radius:y + radius + 1, x - radius:x + radius + 1]
        if patch_white_area.shape != (2 * radius + 1, 2 * radius + 1):
            continue
        if not np.all(patch_white_area):
            continue  # ä¸å®Œå…¨åœ¨ç™½è‰²åŒºåŸŸå†…ï¼Œè·³è¿‡
        
        # è·å–é¢œè‰²å¹¶è®¾ç½®color hint
        raw_color = stroke_array[y, x]
        
        # ç¡®ä¿é¢œè‰²å€¼ä¸ä¸ºç™½è‰²ï¼ˆ255,255,255ï¼‰
        if np.all(raw_color >= 248):
            # å¦‚æœé¢œè‰²å¤ªæ¥è¿‘ç™½è‰²ï¼Œç¨å¾®è°ƒæš—
            color = np.clip(raw_color.astype(np.float32) * 0.9, 0, 255).astype(np.uint8)
        else:
            color = raw_color
            
        # é‡è¦ï¼šåˆ›å»ºä¸€ä¸ªå›ºå®šçº¯è‰²å€¼ï¼Œç¡®ä¿æ•´ä¸ªæ–¹å—éƒ½æ˜¯å®Œå…¨ç›¸åŒçš„é¢œè‰²
        fixed_color = [int(color[0]), int(color[1]), int(color[2])]
        
        # ç›´æ¥å¡«å……æ•´ä¸ªæ–¹å—ä¸ºè¿™ä¸ªçº¯è‰²
        new_cond_array[y - radius:y + radius + 1, x - radius:x + radius + 1] = fixed_color
        
        n_valid += 1
        
        if n_valid >= n_points:
            break  # è¾¾åˆ°æœŸæœ›æ•°é‡å°±åœæ­¢
    
    # è¿”å›PILå›¾åƒ
    if isinstance(original_cond_image, Image.Image):
        return Image.fromarray(new_cond_array.astype(np.uint8))
    else:
        return new_cond_array

def create_color_condition_image(base_image, sketch_data, color_stroke_data):
    """åˆ›å»ºå¸¦é¢œè‰²æç¤ºçš„æ¡ä»¶å›¾åƒ"""
    try:
        if base_image is None or sketch_data is None:
            return None, "è¯·å…ˆå®Œæˆsketchç¼–è¾‘"
        
        # é¦–å…ˆåˆ›å»ºåŸºç¡€çš„maskedå›¾åƒï¼ˆåŒ…å«sketchï¼‰
        masked_image, status = create_masked_image_from_sketch(base_image, sketch_data)
        if masked_image is None:
            return None, f"åˆ›å»ºåŸºç¡€æ¡ä»¶å›¾å¤±è´¥: {status}"
        
        # å¦‚æœæ²¡æœ‰é¢œè‰²ç¬”è§¦æ•°æ®ï¼Œç›´æ¥è¿”å›åŸºç¡€æ¡ä»¶å›¾
        if color_stroke_data is None:
            return masked_image, "ä½¿ç”¨åŸºç¡€æ¡ä»¶å›¾ï¼ˆæ— é¢œè‰²æç¤ºï¼‰"
        
        # å¤„ç†é¢œè‰²ç¬”è§¦æ•°æ®
        color_image = None
        if isinstance(color_stroke_data, dict) and 'composite' in color_stroke_data:
            color_image = color_stroke_data['composite']
        elif isinstance(color_stroke_data, np.ndarray):
            color_image = Image.fromarray(color_stroke_data.astype(np.uint8))
        elif isinstance(color_stroke_data, Image.Image):
            color_image = color_stroke_data
        
        if color_image is None:
            return masked_image, "é¢œè‰²æ•°æ®æ— æ•ˆï¼Œä½¿ç”¨åŸºç¡€æ¡ä»¶å›¾"
        
        # ç¡®ä¿å›¾åƒæ ¼å¼ä¸€è‡´
        if isinstance(color_image, np.ndarray):
            color_image = Image.fromarray(color_image.astype(np.uint8))
        color_image = color_image.resize((1024, 1024)).convert('RGB')
        
        # æå–é¢œè‰²æç¤ºå¹¶ç”Ÿæˆæœ€ç»ˆæ¡ä»¶å›¾
        final_cond_image = extract_color_hints_from_strokes(color_image, masked_image, radius=5, n_points=N_POINTS)
        
        if final_cond_image is None:
            return masked_image, "é¢œè‰²æç¤ºæå–å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¡ä»¶å›¾"
        
        return final_cond_image, "âœ… æ¡ä»¶å›¾å·²ç”Ÿæˆï¼ˆåŒ…å«é¢œè‰²æç¤ºï¼‰"
        
    except Exception as e:
        return None, f"åˆ›å»ºé¢œè‰²æ¡ä»¶å›¾å¤±è´¥: {str(e)}"

def save_condition_image(cond_image):
    """ä¿å­˜æ¡ä»¶å›¾åƒä¸ºPNGæ ¼å¼"""
    if cond_image is None:
        return None, "æ²¡æœ‰æ¡ä»¶å›¾å¯ä»¥ä¿å­˜"
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs("gradio_output", exist_ok=True)
    
    try:
        filename = f"gradio_output/condition_{timestamp}.png"
        if isinstance(cond_image, np.ndarray):
            cond_pil = Image.fromarray(cond_image.astype(np.uint8))
        else:
            cond_pil = cond_image
        
        cond_pil.save(filename, format='PNG', optimize=True)
        return filename, f"âœ… æ¡ä»¶å›¾å·²ä¿å­˜ä¸º: {filename}"
    except Exception as e:
        return None, f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

def generate_image(prompt, num_steps, guidance_scale):
    """ç”Ÿæˆå›¾åƒçš„ä¸»å‡½æ•° - ä½¿ç”¨ç¡®è®¤çš„é¢œè‰²æ¡ä»¶å›¾"""
    global edit_confirmed, color_confirmed, current_edit_data, current_color_data
    
    try:
        print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆå›¾åƒ...")
        
        # æ£€æŸ¥ç¼–è¾‘ç¡®è®¤çŠ¶æ€
        if not edit_confirmed or current_edit_data is None:
            return None, None, "âŒ è¯·å…ˆç‚¹å‡»'ç¡®è®¤ç¼–è¾‘å®Œæˆ'æŒ‰é’®"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é¢œè‰²æ¡ä»¶å›¾
        if not color_confirmed or current_color_data is None:
            return None, None, "âŒ è¯·å…ˆç‚¹å‡»'ç¡®è®¤é¢œè‰²æç¤º'æŒ‰é’®"
        
        base_image = current_edit_data['base_image']
        sketch_data = current_edit_data['sketch_data']
        
        if not prompt.strip():
            return None, None, "âŒ è¯·è¾“å…¥promptæè¿°"
        
        # åˆå§‹åŒ–pipeline - å¼ºåˆ¶CUDAæ£€æŸ¥
        print("â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        try:
            success, init_msg = initialize_pipeline()
            if not success:
                return None, None, init_msg
            print(init_msg)
        except Exception as init_error:
            print(f"Pipelineåˆå§‹åŒ–é”™è¯¯: {init_error}")
            return None, None, f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(init_error)}"
        
        print("ğŸ–¼ï¸ ä½¿ç”¨å†…å­˜ä¸­çš„æ¡ä»¶å›¾ï¼ˆæ— éœ€PNGæ–‡ä»¶ï¼‰...")
        try:
            if current_color_data is None or 'condition_image' not in current_color_data:
                return None, None, "âŒ æ¡ä»¶å›¾ç¼ºå¤±ï¼Œè¯·é‡æ–°ç”Ÿæˆé¢œè‰²æç¤º"

            masked_image = current_color_data['condition_image']
            # ç¡®ä¿ä¸ºPILå›¾åƒ
            if isinstance(masked_image, np.ndarray):
                masked_image = Image.fromarray(masked_image.astype(np.uint8))
            masked_image = masked_image.convert('RGB').resize((1024, 1024))
            print(f"âœ… å·²åŠ è½½å†…å­˜æ¡ä»¶å›¾ï¼Œå°ºå¯¸: {masked_image.size}")

        except Exception as mask_error:
            print(f"æ¡ä»¶å›¾åŠ è½½é”™è¯¯: {mask_error}")
            return None, None, f"âŒ æ¡ä»¶å›¾åŠ è½½å¤±è´¥: {str(mask_error)}"
        
        print("ğŸ¯ å‡†å¤‡ç”Ÿæˆæ¡ä»¶...")
        # åˆ›å»ºcondition - æ·»åŠ å®‰å…¨æ£€æŸ¥
        try:
            # ç¡®ä¿LoRAé€‚é…å™¨æ­£ç¡®åŠ è½½
            if hasattr(pipe, 'set_adapters'):
                pipe.set_adapters("sketch")
            condition = Condition(masked_image, "sketch")
        except Exception as condition_error:
            print(f"æ¡ä»¶å‡†å¤‡é”™è¯¯: {condition_error}")
            return None, None, f"âŒ æ¡ä»¶å‡†å¤‡å¤±è´¥: {str(condition_error)}"
        
        # è®¾ç½®éšæœºç§å­
        seed_everything(42)
        
        # ç”Ÿæˆå›¾åƒ - æ·»åŠ è¿›åº¦æç¤º
        print(f"ğŸš€ æ­£åœ¨ç”Ÿæˆå›¾åƒ (æ­¥æ•°: {int(num_steps)}, å¼•å¯¼å¼ºåº¦: {guidance_scale})")
        print(f"ğŸ“ Prompt: {prompt}")
        
        try:
            # ä½¿ç”¨torch.no_grad()ä¼˜åŒ–å†…å­˜ä½¿ç”¨
            with torch.no_grad():
                result = generate(
                    pipe,
                    prompt=prompt,
                    conditions=[condition],
                    height=1024,
                    width=1024,
                    num_inference_steps=int(num_steps),
                    guidance_scale=guidance_scale,
                )
            
            if result is None or len(result.images) == 0:
                return None, None, "âŒ ç”Ÿæˆå¤±è´¥ï¼šæ¨¡å‹è¿”å›ç©ºç»“æœ"
                
            result_img = result.images[0]
            print("âœ… å›¾åƒç”Ÿæˆå®Œæˆ")
            
        except Exception as gen_error:
            print(f"ç”Ÿæˆè¿‡ç¨‹é”™è¯¯: {gen_error}")
            # æ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            return None, None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(gen_error)}"
        
        print("ğŸ”— æ­£åœ¨åˆ›å»ºå¯¹æ¯”å›¾...")
        # åˆ›å»ºå¯¹æ¯”å›¾åƒ - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        try:
            concat_image = Image.new("RGB", (1024 * 3, 1024))
            base_resized = base_image.resize((1024, 1024)).convert('RGB') if base_image else Image.new("RGB", (1024, 1024), (255, 255, 255))
            concat_image.paste(base_resized, (0, 0))
            # ä¸­é—´å±•ç¤ºï¼šä½¿ç”¨ç”Ÿæˆé¢œè‰²æç¤ºå—å‰çš„åŸå§‹å¸¦é¢œè‰²ç¬”è§¦å›¾ï¼ˆæ¥è‡ªcurrent_color_data['color_stroke_data']ï¼‰
            stroke_img = None
            try:
                if current_color_data and 'color_stroke_data' in current_color_data and current_color_data['color_stroke_data'] is not None:
                    stroke_raw = current_color_data['color_stroke_data']
                    if isinstance(stroke_raw, dict) and 'composite' in stroke_raw:
                        stroke_img = stroke_raw['composite']
                    elif isinstance(stroke_raw, np.ndarray):
                        stroke_img = Image.fromarray(stroke_raw.astype(np.uint8))
                    elif isinstance(stroke_raw, Image.Image):
                        stroke_img = stroke_raw
                # å¦‚æœæ²¡æœ‰raw strokeå›¾åƒï¼Œå›é€€åˆ°maskå›¾
                if stroke_img is None:
                    stroke_img = masked_image
                if isinstance(stroke_img, np.ndarray):
                    stroke_img = Image.fromarray(stroke_img.astype(np.uint8))
                stroke_img = stroke_img.resize((1024, 1024)).convert('RGB')
            except Exception:
                stroke_img = masked_image

            concat_image.paste(stroke_img, (1024, 0))
            concat_image.paste(result_img, (1024 * 2, 0))
        except Exception as concat_error:
            print(f"å¯¹æ¯”å›¾åˆ›å»ºé”™è¯¯: {concat_error}")
            # å³ä½¿å¯¹æ¯”å›¾å¤±è´¥ï¼Œä¹Ÿè¿”å›ç”Ÿæˆç»“æœ
            return result_img, None, "âš ï¸ ç”ŸæˆæˆåŠŸï¼Œä½†å¯¹æ¯”å›¾åˆ›å»ºå¤±è´¥"
        
        # ä¼˜åŒ–ä¿å­˜é€»è¾‘ - å¼‚æ­¥ä¿å­˜ï¼Œé¿å…é˜»å¡GradioçŠ¶æ€
        try:
            import threading
            
            def save_images_async():
                try:
                    os.makedirs("gradio_output", exist_ok=True)
                    result_img.save("gradio_output/result.jpg", quality=95, optimize=True)
                    concat_image.save("gradio_output/comparison.jpg", quality=95, optimize=True)
                    print("ğŸ’¾ ç»“æœå·²å¼‚æ­¥ä¿å­˜åˆ° gradio_output/")
                except Exception as save_error:
                    print(f"å¼‚æ­¥ä¿å­˜é”™è¯¯: {save_error}")
            
            # å¯åŠ¨åå°ä¿å­˜çº¿ç¨‹ï¼Œä¸é˜»å¡ä¸»æµç¨‹
            save_thread = threading.Thread(target=save_images_async, daemon=True)
            save_thread.start()
            
        except Exception as save_error:
            print(f"ä¿å­˜çº¿ç¨‹å¯åŠ¨å¤±è´¥: {save_error}")
            # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›ç»“æœ
        
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return result_img, concat_image, "ğŸ‰ ç”ŸæˆæˆåŠŸï¼"
        
    except Exception as e:
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        # å‘ç”Ÿé”™è¯¯æ—¶æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        return None, None, error_msg

def update_sketch_pad(base_image):
    """å½“ä¸Šä¼ æ–°å›¾åƒæ—¶ï¼Œæ›´æ–°ç»˜åˆ¶ç”»å¸ƒçš„èƒŒæ™¯å¹¶é‡ç½®ç¼–è¾‘çŠ¶æ€"""
    global edit_confirmed, current_edit_data, last_sketch_hash
    
    # é‡ç½®ç¼–è¾‘çŠ¶æ€
    edit_confirmed = False
    current_edit_data = None
    last_sketch_hash = None
    
    if base_image is None:
        return np.ones((1024, 1024, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
    
    # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
    if isinstance(base_image, Image.Image):
        # è°ƒæ•´åˆ°1024 * 1024å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        resized_image = base_image.resize((1024, 1024)).convert('RGB')
        return np.array(resized_image)
    elif isinstance(base_image, np.ndarray):
        return base_image
    else:
        return np.ones((1024, 1024, 3), dtype=np.uint8) * 255

def check_sketch_changes(sketch_data):
    """æ£€æµ‹ç¼–è¾‘åŒºåŸŸæ˜¯å¦æœ‰å˜åŒ–ï¼Œå¹¶é‡ç½®ç¡®è®¤çŠ¶æ€"""
    global edit_confirmed, last_sketch_hash
    import hashlib
    import time
    
    if sketch_data is None:
        return "â³ ç­‰å¾…ç¼–è¾‘..."
    
    try:
        # è®¡ç®—å½“å‰ç¼–è¾‘æ•°æ®çš„å“ˆå¸Œå€¼
        if isinstance(sketch_data, dict) and 'composite' in sketch_data:
            data_to_hash = sketch_data['composite']
        else:
            data_to_hash = sketch_data
            
        if isinstance(data_to_hash, np.ndarray):
            current_hash = hashlib.md5(data_to_hash.tobytes()).hexdigest()
        else:
            current_hash = str(hash(str(data_to_hash)))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
        if last_sketch_hash != current_hash:
            if last_sketch_hash is not None:  # ä¸æ˜¯ç¬¬ä¸€æ¬¡
                edit_confirmed = False  # é‡ç½®ç¡®è®¤çŠ¶æ€
                timestamp = time.strftime("%H:%M:%S")
                print(f"ğŸ”„ [{timestamp}] æ£€æµ‹åˆ°ç¼–è¾‘å˜åŒ–ï¼Œé‡ç½®ç¡®è®¤çŠ¶æ€")
                return "ğŸ”„ æ£€æµ‹åˆ°ç¼–è¾‘å˜åŒ–ï¼Œè¯·é‡æ–°ç¡®è®¤ç¼–è¾‘"
            last_sketch_hash = current_hash
            
        if edit_confirmed:
            return "âœ… ç¼–è¾‘å·²ç¡®è®¤"
        else:
            return "â³ è¯·ç‚¹å‡»ç¡®è®¤ç¼–è¾‘æŒ‰é’®"
            
    except Exception as e:
        return f"âš ï¸ çŠ¶æ€æ£€æŸ¥é”™è¯¯: {str(e)}"

def get_current_status():
    """è·å–å½“å‰å®Œæ•´çŠ¶æ€ - ç‹¬ç«‹æŸ¥è¯¢å‡½æ•°ï¼Œä¸ä¾èµ–ç½‘ç»œåŒæ­¥"""
    global edit_confirmed, color_confirmed, current_edit_data, current_color_data, status_check_counter
    import time
    
    status_check_counter += 1
    timestamp = time.strftime("%H:%M:%S")
    
    # çŠ¶æ€æ£€æŸ¥é€»è¾‘
    if edit_confirmed and color_confirmed and current_edit_data and current_color_data:
        main_status = f"âœ… [{timestamp}] å…¨éƒ¨ç¡®è®¤å®Œæˆ - æ£€æŸ¥#{status_check_counter}"
        edit_status = "âœ… ç¼–è¾‘å·²ç¡®è®¤"
        color_status = "âœ… é¢œè‰²å·²ç¡®è®¤ï¼Œå¯ä»¥ç”Ÿæˆå›¾åƒ"
        network_status = "ğŸŸ¢ çŠ¶æ€åŒæ­¥æ­£å¸¸"
    elif edit_confirmed and current_edit_data:
        main_status = f"ğŸŸ¡ [{timestamp}] ç¼–è¾‘å·²ç¡®è®¤ï¼Œç­‰å¾…é¢œè‰²æç¤º - æ£€æŸ¥#{status_check_counter}"
        edit_status = "âœ… ç¼–è¾‘å·²ç¡®è®¤"
        color_status = "â³ è¯·æ·»åŠ é¢œè‰²æç¤ºå¹¶ç¡®è®¤"
        network_status = "ï¿½ ç­‰å¾…é¢œè‰²ç¡®è®¤"
    else:
        main_status = f"â³ [{timestamp}] ç­‰å¾…ç¼–è¾‘ç¡®è®¤ - æ£€æŸ¥#{status_check_counter}"
        edit_status = "â³ è¯·å®Œæˆç¼–è¾‘å¹¶ç¡®è®¤"
        color_status = "â³ ç­‰å¾…ç¼–è¾‘å®Œæˆ"
        network_status = f"ğŸŸ¡ æœªç¡®è®¤çŠ¶æ€ - æ£€æŸ¥#{status_check_counter}"
    
    print(f"ğŸ“Š [{timestamp}] çŠ¶æ€æŸ¥è¯¢#{status_check_counter}: edit={edit_confirmed}, color={color_confirmed}")
    return main_status, edit_status, color_status, network_status

def backup_state():
    """å¤‡ä»½å½“å‰çŠ¶æ€åˆ°æœ¬åœ°"""
    global local_backup, edit_confirmed, current_edit_data, last_sketch_hash, last_operation_time
    import time
    
    last_operation_time = time.time()
    local_backup = {
        'edit_confirmed': edit_confirmed,
        'current_edit_data': current_edit_data,
        'last_sketch_hash': last_sketch_hash,
        'timestamp': last_operation_time
    }
    print(f"ğŸ’¾ çŠ¶æ€å·²å¤‡ä»½: confirmed={edit_confirmed}")

def restore_state():
    """ä»æœ¬åœ°å¤‡ä»½æ¢å¤çŠ¶æ€"""
    global local_backup, edit_confirmed, current_edit_data, last_sketch_hash
    import time
    
    if local_backup and time.time() - local_backup.get('timestamp', 0) < 300:  # 5åˆ†é’Ÿå†…çš„å¤‡ä»½æœ‰æ•ˆ
        edit_confirmed = local_backup.get('edit_confirmed', False)
        current_edit_data = local_backup.get('current_edit_data')
        last_sketch_hash = local_backup.get('last_sketch_hash')
        print(f"ğŸ“¥ çŠ¶æ€å·²æ¢å¤: confirmed={edit_confirmed}")
        return True
    return False

def continue_editing(base_image):
    """é‡æ–°ç¼–è¾‘ - å®Œå…¨é‡ç½®æ‰€æœ‰çŠ¶æ€"""
    global edit_confirmed, color_confirmed, current_edit_data, current_color_data, last_sketch_hash, last_color_hash, refresh_counter
    import time
    
    timestamp = time.strftime("%H:%M:%S")
    print(f"ğŸ”„ [{timestamp}] é‡æ–°ç¼–è¾‘ - é‡ç½®æ‰€æœ‰çŠ¶æ€")
    
    # å®Œå…¨é‡ç½®æ‰€æœ‰çŠ¶æ€
    edit_confirmed = False
    color_confirmed = False
    current_edit_data = None
    current_color_data = None
    last_sketch_hash = None
    last_color_hash = None
    refresh_counter += 1
    
    # æ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # å‡†å¤‡UIæ›´æ–°æ•°æ®
    main_status = f"ğŸ”„ [{timestamp}] å·²é‡ç½® (åˆ·æ–°#{refresh_counter})"
    edit_status = "â³ è¯·å®Œæˆç¼–è¾‘å¹¶ç¡®è®¤"
    color_status = "â³ ç­‰å¾…ç¼–è¾‘å®Œæˆ"
    network_status = "ğŸŸ¢ çŠ¶æ€å·²é‡ç½®"
    
    # æ¢å¤åŸå›¾
    sketch_pad_result = update_sketch_pad(base_image)
    color_pad_result = update_sketch_pad(base_image)
    
    print(f"âœ… [{timestamp}] é‡ç½®å®Œæˆ (åˆ·æ–°#{refresh_counter})")
    
    return sketch_pad_result, main_status, edit_status, color_status, network_status, color_pad_result, None, ""

def confirm_edit_ready(base_image, sketch_data):
    """ç¡®è®¤ç¼–è¾‘å°±ç»ª - ç®€åŒ–ç‰ˆæœ¬"""
    global edit_confirmed, current_edit_data, last_sketch_hash, color_confirmed, current_color_data
    
    import time
    import hashlib
    from datetime import datetime
    timestamp = time.strftime("%H:%M:%S")
    
    print(f"âœ… [{timestamp}] å¼€å§‹ç¡®è®¤ç¼–è¾‘")
    
    # é‡ç½®çŠ¶æ€
    edit_confirmed = False
    current_edit_data = None
    color_confirmed = False
    current_color_data = None
    
    if base_image is None:
        return "âŒ è¯·å…ˆä¸Šä¼ åŸºç¡€å›¾åƒ", None
    
    if sketch_data is None:
        return "âŒ è¯·å…ˆåœ¨å›¾åƒä¸Šè¿›è¡Œç¼–è¾‘", None
    
    try:
        # å¤„ç†ç¼–è¾‘æ•°æ®
        masked_image, status = create_masked_image_from_sketch(base_image, sketch_data)
        
        if masked_image is None:
            return f"âŒ ç¼–è¾‘æ•°æ®æ— æ•ˆ: {status}", None
        
        # ä¿å­˜åŸºç¡€æ¡ä»¶å›¾ä¸ºPNG
        os.makedirs("condition_images", exist_ok=True)
        file_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_condition_png_path = f"condition_images/base_condition_{file_timestamp}.png"
        
        if isinstance(masked_image, np.ndarray):
            masked_pil = Image.fromarray(masked_image.astype(np.uint8))
        else:
            masked_pil = masked_image
        
        masked_pil.save(base_condition_png_path, format='PNG', optimize=True)
        
        # æ›´æ–°çŠ¶æ€
        edit_confirmed = True
        current_hash = hashlib.md5(str(time.time()).encode()).hexdigest()[:8]
        last_sketch_hash = current_hash
        
        current_edit_data = {
            'base_image': base_image,
            'sketch_data': sketch_data,
            'masked_image': masked_image,
            'base_condition_png_path': base_condition_png_path,
            'hash': current_hash,
            'timestamp': timestamp
        }
        
        success_msg = f"âœ… [{timestamp}] ç¼–è¾‘å·²ç¡®è®¤ï¼{status}"
        print(f"âœ… [{timestamp}] ç¡®è®¤å®Œæˆ")
        
        return success_msg, masked_image
        
    except Exception as e:
        edit_confirmed = False
        error_msg = f"âŒ [{timestamp}] ç¡®è®¤å¤±è´¥: {str(e)}"
        print(error_msg)
        return error_msg, None

def generate_color_hints_from_strokes(color_stroke_data):
    """ä»é¢œè‰²ç¬”è§¦ç”Ÿæˆé¢œè‰²æç¤ºå—"""
    global edit_confirmed, current_edit_data, color_confirmed, current_color_data
    
    import time
    from datetime import datetime
    timestamp = time.strftime("%H:%M:%S")
    
    print(f"ğŸ¨ [{timestamp}] ç”Ÿæˆé¢œè‰²æç¤ºå—")
    
    if not edit_confirmed or current_edit_data is None:
        return "âŒ è¯·å…ˆç¡®è®¤ç¼–è¾‘å®Œæˆ", None
    
    try:
        base_image = current_edit_data['base_image']
        sketch_data = current_edit_data['sketch_data']
        masked_image = current_edit_data['masked_image']
        
        if color_stroke_data is None:
            condition_image = masked_image
            status_msg = "âš ï¸ æ²¡æœ‰é¢œè‰²ç¬”è§¦ï¼Œä½¿ç”¨åŸºç¡€æ¡ä»¶å›¾"
        else:
            condition_image, status = create_color_condition_image(base_image, sketch_data, color_stroke_data)

            if condition_image is None:
                return f"âŒ é¢œè‰²æ¡ä»¶å›¾åˆ›å»ºå¤±è´¥: {status}", None

            status_msg = f"âœ… é¢œè‰²æç¤ºå—å·²ç”Ÿæˆï¼{status}"

        # ä¸å†ä¿å­˜ä¸ºPNGæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨å†…å­˜ä¸­çš„æ¡ä»¶å›¾
        # æ›´æ–°é¢œè‰²æ¡ä»¶æ•°æ®å¹¶è‡ªåŠ¨ç¡®è®¤
        color_confirmed = True
        current_color_data = {
            'condition_image': condition_image,
            'color_stroke_data': color_stroke_data,
            'timestamp': timestamp,
            'confirmed': True
        }

        final_msg = f"{status_msg} (å·²è‡ªåŠ¨ç¡®è®¤ï¼Œå¹¶ä½¿ç”¨å†…å­˜æ¡ä»¶å›¾)"
        print(f"âœ… [{timestamp}] é¢œè‰²æç¤ºå—ç”Ÿæˆå¹¶è‡ªåŠ¨ç¡®è®¤å®Œæˆ")

        return final_msg, condition_image
        
    except Exception as e:
        error_msg = f"âŒ [{timestamp}] ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        return error_msg, None

def confirm_color_hints_ready():
    """ç¡®è®¤é¢œè‰²æç¤ºå‡†å¤‡å°±ç»ª"""
    global color_confirmed, current_color_data
    
    import time
    timestamp = time.strftime("%H:%M:%S")
    
    print(f"âœ… [{timestamp}] ç¡®è®¤é¢œè‰²æç¤º")
    
    if current_color_data is None:
        return "âŒ è¯·å…ˆç‚¹å‡»'ç”Ÿæˆé¢œè‰²æç¤ºå—'æŒ‰é’®", None
    
    try:
        color_confirmed = True
        current_color_data['confirmed'] = True
        
        condition_image = current_color_data['condition_image']
        
        success_msg = f"âœ… [{timestamp}] é¢œè‰²æç¤ºå·²ç¡®è®¤ï¼å¯ä»¥ç”Ÿæˆå›¾åƒ"
        print(f"âœ… [{timestamp}] é¢œè‰²ç¡®è®¤å®Œæˆ")
        
        return success_msg, condition_image
        
    except Exception as e:
        color_confirmed = False
        error_msg = f"âŒ [{timestamp}] ç¡®è®¤å¤±è´¥: {str(e)}"
        print(error_msg)
        return error_msg, None

# åˆ›å»ºGradioç•Œé¢
def create_ui():
    with gr.Blocks(title="OminiControl Inpainting Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ¨ OminiControl Inpainting Demo")
        gr.Markdown("**ä½¿ç”¨è¯´æ˜**: ä¸Šä¼ å›¾åƒ â†’ ç¼–è¾‘mask/sketchå¹¶ç¡®è®¤ â†’ æ·»åŠ é¢œè‰²å¹¶ç”Ÿæˆé¢œè‰²å— â†’ ç¡®è®¤é¢œè‰² â†’ ç”Ÿæˆå›¾åƒ | **å“åº”æ…¢?** ç‚¹å‡»ğŸ“ŠæŸ¥è¯¢çŠ¶æ€")
        
        # æ¨ªå‘å¸ƒå±€ï¼šä¸Šä¼ å›¾åƒã€sketchç¼–è¾‘åŒºã€colorç¼–è¾‘åŒº
        with gr.Row():
            with gr.Column(scale=1):
                base_image = gr.Image(
                    label="ğŸ“¤ 1. ä¸Šä¼ åŸºç¡€å›¾åƒ",
                    type="pil",
                    height=768,
                    width=768
                )
            with gr.Column(scale=1):
                sketch_pad = gr.ImageEditor(
                    label="ğŸ–Œï¸ 2. åœ¨åŸå›¾ä¸Šç¼–è¾‘ (ç™½ç¬”æ¶‚æŠ¹maskåŒºåŸŸï¼Œé»‘ç¬”å‹¾å‹’sketch)",
                    type="numpy",
                    height=768,
                    brush=gr.Brush(
                        default_size=15,
                        colors=["#FFFFFF", "#000000"],
                        default_color="#FFFFFF"
                    ),
                    value=np.ones((1024, 1024, 3), dtype=np.uint8) * 255
                )
            with gr.Column(scale=1):
                color_pad = gr.ImageEditor(
                    label="ğŸ¨ 4. æ·»åŠ é¢œè‰²æç¤º (åœ¨maskåŒºåŸŸç”»é¢œè‰²ç¬”è§¦)",
                    type="numpy",
                    height=768,
                    brush=gr.Brush(
                        default_size=10,
                        colors=["#FF0000", "#00FF00", "#0000FF", "#FFFF00", "#FF00FF", "#00FFFF", "#FFA500", "#800080"],
                        default_color="#FF0000"
                    ),
                    value=np.ones((1024, 1024, 3), dtype=np.uint8) * 255
                )
            
            # final condition image display removed (kept in memory only)


        # ä¸“é—¨çš„ä¸€æ ï¼šå±•ç¤ºç”Ÿæˆçš„å¸¦é¢œè‰²æç¤ºçš„æ¡ä»¶å›¾ï¼ˆä¿å­˜åœ¨å†…å­˜ä¸­ï¼‰
        with gr.Row():
            condition_preview = gr.Image(
                label="ğŸ” ç”Ÿæˆçš„æ¡ä»¶å›¾ï¼ˆå«é¢œè‰²æç¤ºï¼‰",
                type="pil",
                height=512,
                width=512
            )


        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ 
        with gr.Row():
            clear_btn = gr.Button("ğŸ—‘ï¸ é‡ç½®ä¸ºåŸå›¾", variant="secondary", size="sm")
            confirm_btn = gr.Button("âœ… ç¡®è®¤ç¼–è¾‘", variant="primary", size="sm")
            # generate_color_btn moved to dedicated section with n_points slider
        
        # é¢œè‰²æç¤ºæ§åˆ¶åŒºåŸŸ
        gr.Markdown("### ğŸ¨ é¢œè‰²æç¤ºè®¾ç½®")
        with gr.Row():
            with gr.Column(scale=2):
                n_points_slider = gr.Slider(
                                minimum=1,
                                maximum=70,
                                value=N_POINTS,
                                step=1,
                                label="ğŸ¯ é¢œè‰²æç¤ºå—æ•°é‡",
                                info="æ§åˆ¶ä»é¢œè‰²ç¬”è§¦ä¸­æå–å¤šå°‘ä¸ªé¢œè‰²æ–¹å—ï¼ˆ1-70ä¸ªï¼‰"
                            )
            with gr.Column(scale=1):
                confirm_generate_color_btn = gr.Button(
                    "ğŸ¨ ç¡®è®¤ç”Ÿæˆé¢œè‰²æç¤ºå—", 
                    variant="primary", 
                    size="lg"
                )
        
        # å‚æ•°æ§åˆ¶åŒºåŸŸ
        gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
        with gr.Row():
            with gr.Column(scale=2):
                prompt = gr.Textbox(
                    label="âœï¸ è¾“å…¥Promptæè¿°",
                    placeholder="æè¿°ä½ æƒ³è¦åœ¨maskåŒºåŸŸç”Ÿæˆçš„å†…å®¹ï¼Œä¾‹å¦‚ï¼šA beautiful flower vase",
                    lines=2,
                    value="A beautiful vase"
                )
            with gr.Column(scale=1):
                num_steps = gr.Slider(
                    minimum=10,
                    maximum=50,
                    value=28,
                    step=1,
                    label="æ¨ç†æ­¥æ•°"
                )
            with gr.Column(scale=1):
                guidance_scale = gr.Slider(
                    minimum=1.0,
                    maximum=10.0,
                    value=3.5,
                    step=0.1,
                    label="å¼•å¯¼å¼ºåº¦"
                )
        
        # ç”ŸæˆæŒ‰é’®
        with gr.Row():
            generate_btn = gr.Button("ğŸš€ ç”Ÿæˆå›¾åƒ", variant="primary", size="lg")
        
        # çŠ¶æ€æ˜¾ç¤º
        with gr.Row():
            status_text = gr.Textbox(
                label="ğŸ“ çŠ¶æ€ä¿¡æ¯",
                value="è¯·ä¸Šä¼ å›¾åƒå¹¶ç»˜åˆ¶maskåŒºåŸŸ",
                interactive=False,
                lines=1
            )
        
        # ï¼ˆå·²ç®€åŒ–ï¼‰ä¸»çŠ¶æ€ä½¿ç”¨ä¸Šé¢çš„ `status_text`
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ - æ”¹ä¸ºç«–ç›´å¸ƒå±€
        gr.Markdown("### ğŸ“Š ç»“æœå±•ç¤º")
        
        with gr.Tabs():
            with gr.TabItem("ğŸ“¸ ç”Ÿæˆç»“æœ"):
                output_image = gr.Image(
                    label="ç”Ÿæˆçš„å›¾åƒ",
                    type="pil",
                    height=600,  # å¢å¤§æ˜¾ç¤ºé«˜åº¦
                    width=600
                )
                # åœ¨ç”Ÿæˆç»“æœä¸‹æ–¹æ·»åŠ é‡æ–°ç¼–è¾‘æŒ‰é’®
                with gr.Row():
                    continue_edit_btn = gr.Button("ğŸ”„ é‡æ–°ç¼–è¾‘", variant="primary", size="lg")
            
            with gr.TabItem("ï¿½ å¯¹æ¯”å›¾"):
                comparison_image = gr.Image(
                    label="å¯¹æ¯”å›¾ (åŸå›¾|ç¼–è¾‘å›¾|ç”Ÿæˆç»“æœ)",
                    type="pil", 
                    height=400,  # å¯¹æ¯”å›¾ç¨å°ä¸€äº›ï¼Œå› ä¸ºæ˜¯æ¨ªå‘æ‹¼æ¥çš„
                )
        
        # ç¤ºä¾‹åŒºåŸŸ
        gr.Markdown("### ğŸ’¡ ç¤ºä¾‹")
        gr.Examples(
            examples=[
                ["assets/vase.jpg", "A crystal vase with roses"],
                ["assets/room_corner.jpg", "A modern floor lamp"],
            ],
            inputs=[base_image, prompt],
            label="ç‚¹å‡»åŠ è½½ç¤ºä¾‹"
        )
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### æ­¥éª¤è¯´æ˜:
            1. **ä¸Šä¼ å›¾åƒ**: é€‰æ‹©ä½ æƒ³è¦ç¼–è¾‘çš„åŸºç¡€å›¾åƒ
            2. **åœ¨åŸå›¾ä¸Šç¼–è¾‘**: 
               - ä½¿ç”¨**ç™½è‰²ç”»ç¬”**æ¶‚æŠ¹éœ€è¦ä¿®å¤/æ›¿æ¢çš„åŒºåŸŸï¼ˆmaskåŒºåŸŸï¼‰
               - ä½¿ç”¨**é»‘è‰²ç»†ç”»ç¬”**åœ¨maskåŒºåŸŸå†…å‹¾å‹’ä½ æƒ³è¦çš„å†…å®¹è½®å»“
               - å®Œæˆåç‚¹å‡»ç¼–è¾‘å™¨ä¸‹æ–¹çš„"âœ… ç¡®è®¤å‹¾ç”»"æŒ‰é’®
            3. **æ·»åŠ é¢œè‰²æç¤º**: 
               - ç³»ç»Ÿä¼šè‡ªåŠ¨å°†ç¼–è¾‘ç»“æœåŒæ­¥åˆ°é¢œè‰²ç¼–è¾‘å™¨
               - åœ¨é¢œè‰²ç¼–è¾‘å™¨ä¸­ï¼Œä½¿ç”¨**å½©è‰²ç”»ç¬”**åœ¨ç™½è‰²maskåŒºåŸŸå†…æ·»åŠ é¢œè‰²ç¬”è§¦
               - é¢œè‰²ç¬”è§¦ä¼šä½œä¸ºç”Ÿæˆå†…å®¹çš„é¢œè‰²å¼•å¯¼
            4. **è®¾ç½®é¢œè‰²æç¤ºå—æ•°é‡**: ä½¿ç”¨"ğŸ¯ é¢œè‰²æç¤ºå—æ•°é‡"æ»‘æ¡é€‰æ‹©è¦æå–çš„é¢œè‰²æ–¹å—æ•°é‡ï¼ˆ1-70ä¸ªï¼‰
            5. **ç”Ÿæˆé¢œè‰²æç¤ºå—**: ç‚¹å‡»"ğŸ¨ ç¡®è®¤ç”Ÿæˆé¢œè‰²æç¤ºå—"æŒ‰é’®
               - ç³»ç»Ÿä¼šæ ¹æ®è®¾å®šçš„æ•°é‡è‡ªåŠ¨æå–çº¯è‰²æ–¹å—å¹¶ä¿å­˜ä¸ºPNGæ–‡ä»¶
               - **æ–‡ä»¶è·¯å¾„ä¼šæ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼Œå¯ä¸‹è½½æ£€æŸ¥**
            6. **ç¡®è®¤é¢œè‰²æç¤º**: æŸ¥çœ‹ç”Ÿæˆçš„æ¡ä»¶å›¾ï¼Œç¡®è®¤æ— è¯¯åç‚¹å‡»"âœ… ç¡®è®¤é¢œè‰²æç¤º"
            7. **æ£€æŸ¥æ¡ä»¶å›¾**: å¯é€šè¿‡"ğŸ“¥ ä¸‹è½½æ¡ä»¶å›¾PNG"æŒ‰é’®ä¸‹è½½æ£€æŸ¥æœ€ç»ˆè¾“å…¥ç»™æ¨¡å‹çš„æ¡ä»¶å›¾
            8. **è¾“å…¥prompt**: è¯¦ç»†æè¿°ä½ æƒ³åœ¨ç¼–è¾‘åŒºåŸŸç”Ÿæˆçš„å†…å®¹
            9. **è°ƒæ•´å‚æ•°**: 
               - æ¨ç†æ­¥æ•°: å»ºè®®20-30ï¼Œæ›´å¤šæ­¥æ•°è´¨é‡æ›´å¥½ä½†é€Ÿåº¦æ›´æ…¢
               - å¼•å¯¼å¼ºåº¦: å»ºè®®3-5ï¼Œæ§åˆ¶ç”Ÿæˆå†…å®¹ä¸promptçš„ç›¸å…³æ€§
            10. **ç”Ÿæˆå›¾åƒ**: ç‚¹å‡»"ğŸš€ ç”Ÿæˆå›¾åƒ"æŒ‰é’®å¼€å§‹å¤„ç†
               - **æ¨¡å‹å°†è‡ªåŠ¨è¯»å–ä¿å­˜çš„PNGæ¡ä»¶å›¾æ–‡ä»¶**
            11. **é‡æ–°ç¼–è¾‘**: ç”Ÿæˆå®Œæˆåï¼Œç‚¹å‡»"ğŸ”„ é‡æ–°ç¼–è¾‘"æŒ‰é’®å¯é‡æ–°ç¼–è¾‘
            
            ### æ³¨æ„äº‹é¡¹:
            - ç¡®ä¿å·²æ­£ç¡®é…ç½®æ¨¡å‹è·¯å¾„ï¼ˆåœ¨ä»£ç ä¸­ä¿®æ”¹local_pathå’Œlora_pathï¼‰
            - å¿…é¡»å…ˆç”¨ç™½ç¬”æ¶‚æŠ¹åŒºåŸŸï¼Œå†ç”¨é»‘ç¬”å‹¾å‹’ç»†èŠ‚
            - **å·¥ä½œæµç¨‹**: ç¡®è®¤å‹¾ç”» â†’ ç”Ÿæˆé¢œè‰²æç¤ºå— â†’ ç¡®è®¤é¢œè‰²æç¤º â†’ ç”Ÿæˆå›¾åƒ
            - **æ¯ä¸€æ­¥éƒ½æœ‰æ˜ç¡®çš„çŠ¶æ€æç¤ºï¼Œç¡®ä¿ä¸ä¼šå¡æ­»**
            - **æŒ‰é’®ä½ç½®**: ç¡®è®¤å‹¾ç”»åœ¨ç¼–è¾‘å™¨ä¸‹æ–¹ï¼Œé¢œè‰²æŒ‰é’®åœ¨é¢œè‰²ç¼–è¾‘å™¨ä¸‹æ–¹
            - é¢œè‰²æç¤ºä¼šè¢«æå–ä¸º11x11åƒç´ çš„çº¯è‰²æ–¹å—
            - **æ¡ä»¶å›¾ä¼šè‡ªåŠ¨ä¿å­˜ä¸ºPNGæ–‡ä»¶åˆ°condition_images/ç›®å½•**
            - **ç”Ÿæˆæ—¶æ¨¡å‹ç›´æ¥è¯»å–PNGæ–‡ä»¶ï¼Œç¡®ä¿è¾“å…¥ä¸€è‡´æ€§**
            - **å¯é€šè¿‡æ–‡ä»¶è·¯å¾„æ£€æŸ¥æœ€ç»ˆè¾“å…¥ç»™æ¨¡å‹çš„æ¡ä»¶å›¾**
            - å¼ºåˆ¶ä½¿ç”¨CUDAï¼Œç¡®ä¿GPUé©±åŠ¨æ­£ç¡®å®‰è£…
            
            ### ğŸš€ å“åº”æ€§é—®é¢˜è§£å†³æ–¹æ¡ˆ:
            - **ğŸ“Š æŸ¥è¯¢çŠ¶æ€**: ç‹¬ç«‹æ£€æŸ¥å½“å‰çŠ¶æ€ï¼Œä¸ä¾èµ–ç½‘ç»œåŒæ­¥
            - **âœ… ç¡®è®¤å‹¾ç”»**: æç®€ç‰ˆç¡®è®¤ï¼Œå‡å°‘ç½‘ç»œä¾èµ–ï¼Œè‡ªåŠ¨åŒæ­¥åˆ°é¢œè‰²ç¼–è¾‘å™¨
            - **ğŸ¨ ç”Ÿæˆé¢œè‰²æç¤ºå—**: ç‹¬ç«‹ç”Ÿæˆæ­¥éª¤ï¼ŒæŸ¥çœ‹ç»“æœåå†ç¡®è®¤
            - **âœ… ç¡®è®¤é¢œè‰²æç¤º**: æœ€ç»ˆç¡®è®¤æ­¥éª¤ï¼Œç¡®ä¿æ¡ä»¶å›¾æ­£ç¡®
            - **ğŸ”„ é‡æ–°ç¼–è¾‘**: ç”Ÿæˆåé‡ç½®æ‰€æœ‰çŠ¶æ€ï¼Œæµç•…è¿”å›ç¼–è¾‘æ¨¡å¼
            - **å¼‚æ­¥ä¿å­˜**: å›¾ç‰‡åå°ä¿å­˜ï¼Œä¸é˜»å¡ç•Œé¢å“åº”
            - **æŒ‰é’®ä½ç½®ä¼˜åŒ–**: æ¯ä¸ªæŒ‰é’®ç´§è·Ÿå¯¹åº”çš„ç¼–è¾‘å™¨ï¼Œæ“ä½œæ›´ç›´è§‚
            
            ### ğŸ“± æŒ‰é’®ä½¿ç”¨æŒ‡å—:
            1. ç¼–è¾‘å®Œæˆå â†’ ç‚¹å‡»"âœ… ç¡®è®¤ç¼–è¾‘"
            2. æ·»åŠ é¢œè‰²å â†’ è°ƒæ•´"ğŸ¯ é¢œè‰²æç¤ºå—æ•°é‡"æ»‘æ¡é€‰æ‹©é¢œè‰²å—æ•°é‡
            3. ç”Ÿæˆé¢œè‰²å— â†’ ç‚¹å‡»"ğŸ¨ ç¡®è®¤ç”Ÿæˆé¢œè‰²æç¤ºå—"
            4. æŸ¥çœ‹æ¡ä»¶å›¾ â†’ æ£€æŸ¥ç”Ÿæˆçš„æ¡ä»¶å›¾æ˜¯å¦æ­£ç¡®
            5. ç¡®è®¤æ— è¯¯å â†’ ç‚¹å‡»"âœ… ç¡®è®¤é¢œè‰²æç¤º"
            6. æ£€æŸ¥æ–‡ä»¶ â†’ ç‚¹å‡»"ğŸ“¥ ä¸‹è½½æ¡ä»¶å›¾PNG"æŸ¥çœ‹å®é™…è¾“å…¥æ–‡ä»¶
            7. ç”Ÿæˆå®Œæˆå â†’ ç‚¹å‡»"ğŸ”„ é‡æ–°ç¼–è¾‘"é‡æ–°ç¼–è¾‘
            8. è§‚å¯ŸçŠ¶æ€æ  â†’ âœ…è¡¨ç¤ºå·²ç¡®è®¤ï¼Œâ³è¡¨ç¤ºæœªç¡®è®¤
            
            ### ğŸŒ ç½‘ç»œçŠ¶æ€æŒ‡ç¤º:
            - ğŸŸ¢ ç»¿è‰²ï¼šæ­£å¸¸ | ğŸŸ¡ é»„è‰²ï¼šå»¶è¿Ÿ | ğŸ”´ çº¢è‰²ï¼šå¼‚å¸¸
            - çŠ¶æ€å®æ—¶æ›´æ–°ï¼Œæ”¯æŒæ— ç¼ç¼–è¾‘-ç”Ÿæˆ-é‡æ–°ç¼–è¾‘å¾ªç¯
            - **åˆ†æ­¥ç¡®è®¤è®¾è®¡ï¼Œé¿å…çŠ¶æ€æ··ä¹±å’Œå¡æ­»**
            - **æŒ‰é’®å¸ƒå±€ä¼˜åŒ–ï¼Œæ¯ä¸ªç¼–è¾‘å™¨ä¸‹æ–¹éƒ½æœ‰å¯¹åº”çš„ç¡®è®¤æŒ‰é’®**
            """)
        
        # äº‹ä»¶ç»‘å®š - æ·»åŠ æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
        
        # å½“ä¸Šä¼ æ–°å›¾åƒæ—¶ï¼Œè‡ªåŠ¨æ›´æ–°ImageEditorçš„èƒŒæ™¯
        def update_all_pads(base_img):
            """æ›´æ–°æ‰€æœ‰ç¼–è¾‘å™¨"""
            result = update_sketch_pad(base_img)
            return result, result
            
        base_image.change(
            fn=update_all_pads,
            inputs=base_image,
            outputs=[sketch_pad, color_pad],
            show_progress="hidden"
        )
        
        # ç¼–è¾‘åŒºåŸŸå˜åŒ–ç›‘æ§ - ç®€åŒ–ç‰ˆæœ¬
        def check_sketch_and_network(sketch_data):
            """æ£€æŸ¥ç¼–è¾‘å˜åŒ–å¹¶è¿”å›ä¸»çŠ¶æ€å­—ç¬¦ä¸²"""
            sketch_status = check_sketch_changes(sketch_data)
            return sketch_status

        sketch_pad.change(
            fn=check_sketch_and_network,
            inputs=sketch_pad,
            outputs=[status_text],
            show_progress="hidden"
        )
        
        # é‡ç½®æŒ‰é’®
        def reset_and_update_status(base_img):
            """é‡ç½®å¹¶æ›´æ–°çŠ¶æ€"""
            global edit_confirmed, color_confirmed, current_edit_data, current_color_data
            edit_confirmed = False
            color_confirmed = False
            current_edit_data = None
            current_color_data = None
            result = update_sketch_pad(base_img)
            # è¿”å›ï¼šsketch_pad, color_pad, status_text, condition_preview
            return result, result, "ğŸ”„ å·²é‡ç½®ä¸ºåŸå›¾ï¼Œè¯·é‡æ–°ç¼–è¾‘", None

        clear_btn.click(
            fn=reset_and_update_status,
            inputs=base_image,
            outputs=[sketch_pad, color_pad, status_text, condition_preview],
            show_progress="hidden"
        )
        
        
        # çŠ¶æ€æŸ¥è¯¢æŒ‰é’®å·²ç§»é™¤; ä½¿ç”¨ä¸»çŠ¶æ€æ¡† `status_text` æ˜¾ç¤ºçŠ¶æ€
        
        # ç¡®è®¤ç¼–è¾‘æŒ‰é’® - ç®€åŒ–ç‰ˆæœ¬
        def confirm_and_update_status_with_retry(base_img, sketch_data):
            """ç¡®è®¤ç¼–è¾‘å¹¶åŒæ­¥çŠ¶æ€ï¼ˆç®€åŒ–è¿”å›ï¼‰"""
            import time
            start_time = time.time()

            # æ‰§è¡Œç¡®è®¤æ“ä½œ
            main_status, masked_image = confirm_edit_ready(base_img, sketch_data)

            if "âœ…" in main_status:
                # æ›´æ–°é¢œè‰²ç¼–è¾‘å™¨
                if masked_image is not None:
                    if isinstance(masked_image, Image.Image):
                        color_pad_image = np.array(masked_image)
                    else:
                        color_pad_image = masked_image
                else:
                    if base_img is not None and isinstance(base_img, Image.Image):
                        color_pad_image = np.array(base_img.resize((1024, 1024)))
                    else:
                        color_pad_image = np.ones((1024, 1024, 3), dtype=np.uint8) * 255
            else:
                color_pad_image = np.ones((1024, 1024, 3), dtype=np.uint8) * 255

            response_time = time.time() - start_time
            print(f"â±ï¸ ç¡®è®¤å“åº”: {response_time:.2f}ç§’, çŠ¶æ€: {'æˆåŠŸ' if 'âœ…' in main_status else 'å¤±è´¥'}")

            return main_status, color_pad_image

        confirm_btn.click(
            fn=confirm_and_update_status_with_retry,
            inputs=[base_image, sketch_pad],
            outputs=[status_text, color_pad],
            show_progress="minimal"
        )
        
        # ç”Ÿæˆé¢œè‰²æç¤ºå—æŒ‰é’® - ä½¿ç”¨sliderå€¼
        def generate_color_and_update_status(color_stroke_data, n_points_value):
            """ç”Ÿæˆé¢œè‰²æç¤ºå—å¹¶è‡ªåŠ¨ç¡®è®¤é¢œè‰²ï¼ˆä½†ä¸è§¦å‘ç”Ÿæˆï¼‰"""
            global N_POINTS
            import time
            start_time = time.time()

            # æ›´æ–°å…¨å±€N_POINTSå˜é‡
            N_POINTS = int(n_points_value)
            print(f"ğŸ¯ ä½¿ç”¨é¢œè‰²æç¤ºå—æ•°é‡: {N_POINTS}")

            # ç”Ÿæˆé¢œè‰²æ¡ä»¶å›¾å¹¶è‡ªåŠ¨ç¡®è®¤ï¼ˆå†…å­˜ä¸­ï¼‰
            color_msg, condition_img = generate_color_hints_from_strokes(color_stroke_data)
            response_time = time.time() - start_time
            print(f"â±ï¸ é¢œè‰²ç”Ÿæˆå“åº”: {response_time:.2f}ç§’")

            # è¿”å›ï¼šä¸»çŠ¶æ€ï¼ˆä»…è¿”å›çŠ¶æ€ï¼Œæ¡ä»¶å›¾ä¿å­˜åœ¨å†…å­˜current_color_dataï¼‰
            # è¿”å›çŠ¶æ€æ–‡æœ¬å’Œæ¡ä»¶å›¾ä»¥æ›´æ–°é¢„è§ˆï¼ˆæ¡ä»¶å›¾å¯èƒ½ä¸ºNoneï¼‰
            return color_msg, condition_img

        confirm_generate_color_btn.click(
            fn=generate_color_and_update_status,
            inputs=[color_pad, n_points_slider],
            outputs=[status_text, condition_preview],
            show_progress="minimal"
        )
        
        # ç¡®è®¤é¢œè‰²æç¤ºæŒ‰é’® - ç®€åŒ–ç‰ˆæœ¬
        # ç¡®è®¤é¢œè‰²æç¤ºæŒ‰é’®å·²ç§»é™¤; é¢œè‰²å°†åœ¨ç”Ÿæˆé¢œè‰²æç¤ºå—æ—¶è‡ªåŠ¨ç¡®è®¤
        
        # ä¸‹è½½æ¡ä»¶å›¾æŒ‰é’®
        # æ¡ä»¶å›¾PNGä¸‹è½½åŠŸèƒ½å·²ç§»é™¤ï¼ˆä½¿ç”¨å†…å­˜ä¸­çš„æ¡ä»¶å›¾ï¼‰
        
        # ç”ŸæˆæŒ‰é’® - å¢å¼ºçŠ¶æ€åé¦ˆå’ŒåŒæ­¥
        def safe_generate_image_with_status(prompt_text, num_steps, guidance_scale):
            """å®‰å…¨çš„ç”Ÿæˆå›¾åƒåŒ…è£…å‡½æ•°ï¼Œç¡®ä¿å§‹ç»ˆæœ‰æ˜ç¡®åé¦ˆ"""
            import time
            timestamp = time.strftime("%H:%M:%S")
            print(f"ğŸ¯ [{timestamp}] ç”ŸæˆæŒ‰é’®è¢«ç‚¹å‡»...")
            
            try:
                if not edit_confirmed:
                    error_msg = "âŒ è¯·å…ˆç‚¹å‡»'ç¡®è®¤ç¼–è¾‘å®Œæˆ'æŒ‰é’®"
                    return None, None, error_msg

                if not color_confirmed:
                    error_msg = "âŒ è¯·å…ˆç”Ÿæˆé¢œè‰²æç¤ºå—ï¼ˆé¢œè‰²å°†åœ¨ç”Ÿæˆæ—¶è‡ªåŠ¨ç¡®è®¤ï¼‰"
                    return None, None, error_msg

                print(f"â³ [{timestamp}] å¼€å§‹ç”Ÿæˆå›¾åƒ...")
                result_img, comparison_img, main_status = generate_image(prompt_text, num_steps, guidance_scale)

                return result_img, comparison_img, main_status

            except Exception as e:
                error_msg = f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {str(e)}"
                print(f"âŒ [{timestamp}] {error_msg}")
                return None, None, error_msg
        
        generate_event = generate_btn.click(
            fn=safe_generate_image_with_status,
            inputs=[prompt, num_steps, guidance_scale],
            outputs=[output_image, comparison_image, status_text],
            show_progress=True,
            scroll_to_output=True,
        )
        
        # ç»§ç»­ç¼–è¾‘æŒ‰é’® - é‡ç½®çŠ¶æ€å¹¶è¿”å›ç¼–è¾‘æ¨¡å¼
        def continue_editing_wrapper(base_img):
            """ç»§ç»­ç¼–è¾‘çš„åŒ…è£…å‡½æ•°ï¼Œç¡®ä¿è¿”å›å€¼é¡ºåºæ­£ç¡®"""
            sketch_pad_result, main_status, _, _, _, color_pad_result, _, _ = continue_editing(base_img)
            # è¿”å›ï¼šsketch_pad, status_text, color_pad, condition_preview(æ¸…ç©º)
            return sketch_pad_result, main_status, color_pad_result, None

        continue_edit_btn.click(
            fn=continue_editing_wrapper,
            inputs=base_image,
            outputs=[sketch_pad, status_text, color_pad, condition_preview],
            show_progress="hidden"
        )
        
        # é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–ä¸»çŠ¶æ€æ–‡æœ¬
        def load_status_wrapper():
            main_status, *_ = get_current_status()
            return main_status

        demo.load(
            fn=load_status_wrapper,
            inputs=None,
            outputs=[status_text],
            show_progress="hidden"
        )
    
    return demo

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='OminiControl Inpainting Demo')
    parser.add_argument('--cpu', action='store_true', help='åœ¨CPUä¸Šè¿è¡Œï¼ˆé»˜è®¤ä½¿ç”¨GPUï¼‰')
    parser.add_argument('--gpu', action='store_true', help='åœ¨GPUä¸Šè¿è¡Œï¼ˆé»˜è®¤é€‰é¡¹ï¼‰')
    parser.add_argument('--port', type=int, default=7860, help='GradioæœåŠ¡å™¨ç«¯å£ï¼ˆé»˜è®¤7860ï¼‰')
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    if args.cpu:
        USE_CPU = True
        DEVICE = "cpu"
        print("ğŸš€ å¯åŠ¨OminiControl Inpainting Demo (CPUæ¨¡å¼)...")
        print("âš ï¸ CPUæ¨¡å¼è¿è¡Œé€Ÿåº¦è¾ƒæ…¢ï¼Œæ¨èä½¿ç”¨GPU")
    else:
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        if torch.cuda.is_available():
            USE_CPU = False
            DEVICE = "cuda"
            print("ğŸš€ å¯åŠ¨OminiControl Inpainting Demo (GPUæ¨¡å¼)...")
            print(f"âœ… CUDAå¯ç”¨ï¼ŒGPU: {torch.cuda.get_device_name()}")
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
            print("ğŸ’¡ å¦‚éœ€ä½¿ç”¨GPUï¼Œè¯·ç¡®ä¿å®‰è£…äº†æ­£ç¡®çš„GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬")
            USE_CPU = True
            DEVICE = "cpu"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("gradio_output", exist_ok=True)
    os.makedirs("condition_images", exist_ok=True)  # åˆ›å»ºæ¡ä»¶å›¾ä¿å­˜ç›®å½•
    
    # å¯åŠ¨ç•Œé¢
    demo = create_ui()
    print(f"ğŸŒ Gradioç•Œé¢å°†åœ¨ç«¯å£ {args.port} å¯åŠ¨")
    print(f"ğŸ¯ è¿è¡Œè®¾å¤‡: {DEVICE}")
    demo.launch(
        server_name="0.0.0.0",
        server_port=args.port,
        share=False,
        debug=True,
        show_error=True
    )
