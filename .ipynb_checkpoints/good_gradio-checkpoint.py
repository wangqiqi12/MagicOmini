import os
import torch
import gradio as gr
import numpy as np
from diffusers.pipelines import FluxPipeline
from PIL import Image, ImageDraw
import cv2

from omini.pipeline.flux_omini import Condition, generate, seed_everything

# å…¨å±€å˜é‡
pipe = None
edit_confirmed = False  # ç¼–è¾‘ç¡®è®¤çŠ¶æ€
current_edit_data = None  # å½“å‰ç¼–è¾‘æ•°æ®
last_sketch_hash = None  # ä¸Šæ¬¡ç¼–è¾‘æ•°æ®çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æµ‹å˜åŒ–
refresh_counter = 0  # å¼ºåˆ¶åˆ·æ–°è®¡æ•°å™¨
local_backup = {}  # æœ¬åœ°çŠ¶æ€å¤‡ä»½ï¼Œé˜²æ­¢ç½‘ç»œä¸­æ–­ä¸¢å¤±çŠ¶æ€
click_timestamps = []  # ç‚¹å‡»æ—¶é—´æˆ³ï¼Œç”¨äºæ£€æµ‹ç½‘ç»œå»¶è¿Ÿ
status_check_counter = 0  # çŠ¶æ€æ£€æŸ¥è®¡æ•°å™¨
last_operation_time = 0  # æœ€åæ“ä½œæ—¶é—´

def initialize_pipeline():
    """åˆå§‹åŒ–pipeline - å¼ºåˆ¶ä½¿ç”¨CUDAï¼Œè¿”å›çŠ¶æ€ä¿¡æ¯"""
    global pipe
    
    if pipe is not None:
        return True, "âœ… Pipelineå·²å°±ç»ª"
    
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–pipeline...")
    
    try:
        # å¼ºåˆ¶æ£€æŸ¥CUDAå¯ç”¨æ€§
        if not torch.cuda.is_available():
            error_msg = "âŒ CUDAä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿GPUé©±åŠ¨æ­£ç¡®å®‰è£…"
            print(error_msg)
            return False, error_msg
        
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
        
        # NOTE: è¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„
        local_path = "/root/private_data/wangqiqi/Omini_ckpts/FLUX.1-dev"
        
        print(f"ğŸ“‚ åŠ è½½åŸºç¡€æ¨¡å‹: {local_path}")
        # å¼ºåˆ¶ä½¿ç”¨CUDA - ä½¿ç”¨device_mapè‡ªåŠ¨å¤„ç†è®¾å¤‡æ”¾ç½®
        pipe = FluxPipeline.from_pretrained(
            local_path,
            torch_dtype=torch.bfloat16,
            device_map="cuda",  # è‡ªåŠ¨è®¾å¤‡æ˜ å°„ï¼Œä¼šä¼˜å…ˆä½¿ç”¨CUDA
            low_cpu_mem_usage=True,
        )
        
        # éªŒè¯æ¨¡å‹è®¾å¤‡ä¿¡æ¯
        try:
            if hasattr(pipe, 'device'):
                print(f"ğŸ” Pipelineè®¾å¤‡: {pipe.device}")
            elif hasattr(pipe, 'transformer') and hasattr(pipe.transformer, 'device'):
                print(f"ğŸ” Transformerè®¾å¤‡: {pipe.transformer.device}")
            else:
                print("ğŸ” è®¾å¤‡ä¿¡æ¯: ä½¿ç”¨device_mapè‡ªåŠ¨ç®¡ç†")
        except:
            print("ğŸ” è®¾å¤‡ä¿¡æ¯: è‡ªåŠ¨ç®¡ç†ä¸­")
        
        print("ğŸ“¦ åŠ è½½LoRAæƒé‡...")
        # NOTE: è¯·ä¿®æ”¹ä¸ºä½ çš„å®é™…LoRAè·¯å¾„  
        lora_path = "/root/private_data/wangqiqi/MagicOmini/runs/4GPU_bs1_acc8_tot32_1024_1024_r32_sketch_Prodigy/ckpt/15000"
        
        # æ£€æŸ¥LoRAæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        import os
        lora_file = os.path.join(lora_path, "default.safetensors")
        if not os.path.exists(lora_file):
            error_msg = f"âŒ LoRAæ–‡ä»¶ä¸å­˜åœ¨: {lora_file}"
            print(error_msg)
            print("   è¯·æ£€æŸ¥è·¯å¾„æˆ–æƒé‡æ–‡ä»¶å")
            return False, error_msg
        
        pipe.load_lora_weights(
            lora_path,
            weight_name="default.safetensors",
            adapter_name="sketch",
        )
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ä¼˜åŒ–å†…å­˜
        pipe.unet.eval() if hasattr(pipe, 'unet') else None
        pipe.transformer.eval() if hasattr(pipe, 'transformer') else None
        
        # å¯ç”¨å†…å­˜ä¼˜åŒ–ï¼ˆä¸device_mapå…¼å®¹ï¼‰
        try:
            pipe.enable_attention_slicing()
            print("âœ… å·²å¯ç”¨æ³¨æ„åŠ›åˆ‡ç‰‡ä»¥èŠ‚çœå†…å­˜")
        except Exception as e:
            print(f"âš ï¸ æ³¨æ„åŠ›åˆ‡ç‰‡ä¸å¯ç”¨: {e}")
        
        # æ³¨æ„ï¼šä½¿ç”¨device_mapæ—¶ä¸å»ºè®®åŒæ—¶ä½¿ç”¨CPUå¸è½½
        print("ğŸ’¡ ä½¿ç”¨device_mapè‡ªåŠ¨ç®¡ç†å†…å­˜ï¼Œè·³è¿‡CPUå¸è½½")
        
        print("ğŸ‰ Pipelineåˆå§‹åŒ–å®Œæˆ!")
        return True, "âœ… Pipelineåˆå§‹åŒ–å®Œæˆ!"
        
    except FileNotFoundError as e:
        error_msg = f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {str(e)}"
        print(error_msg)
        return False, error_msg
    except torch.cuda.OutOfMemoryError as e:
        error_msg = f"âŒ GPUå†…å­˜ä¸è¶³: {str(e)}"
        print(error_msg)
        print("ğŸ’¡ å»ºè®®: å°è¯•é‡å¯ç¨‹åºæˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
        return False, error_msg
    except Exception as e:
        error_msg = f"âŒ Pipelineåˆå§‹åŒ–å¤±è´¥: {str(e)}"
        print(error_msg)
        return False, error_msg

def create_masked_image_from_sketch(base_image, sketch_data):
    """ä»baseå›¾åƒå’Œç”¨æˆ·ç¼–è¾‘çš„sketchåˆ›å»ºmaskedå›¾åƒ"""
    if base_image is None:
        return None, "è¯·å…ˆä¸Šä¼ åŸºç¡€å›¾åƒ"
    
    if sketch_data is None:
        return None, "è¯·å…ˆåœ¨å›¾åƒä¸Šç¼–è¾‘maskåŒºåŸŸ"
    
    try:
        # å¤„ç†baseå›¾åƒ
        if isinstance(base_image, np.ndarray):
            base_image = Image.fromarray(base_image.astype(np.uint8))
        base_image = base_image.resize((1024, 1024)).convert('RGB')
        
        # å¤„ç†ç”¨æˆ·ç¼–è¾‘åçš„å›¾åƒæ•°æ®
        edited_image = None
        
        print(f"Debug: sketch_data type: {type(sketch_data)}")
        
        if isinstance(sketch_data, dict):
            print(f"Debug: sketch_data keys: {sketch_data.keys()}")
            # å°è¯•å¸¸è§çš„å­—æ®µå - ä¼˜å…ˆä½¿ç”¨compositeï¼ˆåˆæˆå›¾åƒï¼‰
            possible_keys = ['composite', 'image', 'background', 'layers', 'data']
            for key in possible_keys:
                if key in sketch_data and sketch_data[key] is not None:
                    edited_image = sketch_data[key]
                    print(f"Debug: ä½¿ç”¨å­—æ®µ '{key}'")
                    break
        elif isinstance(sketch_data, np.ndarray):
            edited_image = sketch_data
        elif isinstance(sketch_data, Image.Image):
            edited_image = sketch_data
        else:
            edited_image = sketch_data
        
        if edited_image is None:
            return None, "æ— æ³•ä»ç¼–è¾‘æ•°æ®ä¸­æå–å›¾åƒ"
        
        # ç»Ÿä¸€è½¬æ¢ä¸ºPILå›¾åƒ    
        if isinstance(edited_image, np.ndarray):
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            if edited_image.dtype != np.uint8:
                edited_image = (edited_image * 255).astype(np.uint8) if edited_image.max() <= 1 else edited_image.astype(np.uint8)
            edited_image = Image.fromarray(edited_image)
        elif not isinstance(edited_image, Image.Image):
            return None, f"ä¸æ”¯æŒçš„å›¾åƒæ•°æ®ç±»å‹: {type(edited_image)}"
        
        # è°ƒæ•´å°ºå¯¸å’Œæ ¼å¼
        edited_image = edited_image.resize((1024, 1024)).convert('RGB')
        
        # åˆ›å»ºmaskï¼šæ£€æµ‹ç™½è‰²æ¶‚æŠ¹åŒºåŸŸ
        edited_array = np.array(edited_image)
        base_array = np.array(base_image)
        
        # æ‰¾åˆ°ç”¨æˆ·ç”¨ç™½è‰²ç¬”æ¶‚æŠ¹çš„åŒºåŸŸï¼ˆæ¥è¿‘ç™½è‰²çš„åƒç´ ï¼‰
        # ç™½è‰²æ¶‚æŠ¹åŒºåŸŸï¼šRGBå€¼éƒ½å¾ˆé«˜ï¼ˆæ¥è¿‘255ï¼‰
        white_mask = ((edited_array[:,:,0] > 240) & 
                     (edited_array[:,:,1] > 240) & 
                     (edited_array[:,:,2] > 240))
        
        # åŒæ—¶æ’é™¤åŸå›¾ä¸­æœ¬æ¥å°±æ˜¯ç™½è‰²çš„åŒºåŸŸ
        original_white = ((base_array[:,:,0] > 240) & 
                         (base_array[:,:,1] > 240) & 
                         (base_array[:,:,2] > 240))
        
        # çœŸæ­£çš„maskåŒºåŸŸï¼šç¼–è¾‘åæ˜¯ç™½è‰²ä½†åŸå›¾ä¸æ˜¯ç™½è‰²çš„åŒºåŸŸ
        mask_region = white_mask & ~original_white
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ˜æ˜¾çš„ç™½è‰²æ¶‚æŠ¹ï¼Œåˆ™æ£€æµ‹æ‰€æœ‰æ˜æ˜¾å˜åŒ–çš„åŒºåŸŸ
        if np.sum(mask_region) < 100:  # å¦‚æœmaskåŒºåŸŸå¤ªå°
            # è®¡ç®—åƒç´ å·®å¼‚
            diff = np.abs(edited_array.astype(np.float32) - base_array.astype(np.float32))
            diff_magnitude = np.sum(diff, axis=2)
            # æ‰¾åˆ°å·®å¼‚è¾ƒå¤§çš„åŒºåŸŸï¼ˆç”¨æˆ·ç¼–è¾‘è¿‡çš„åŒºåŸŸï¼‰
            mask_region = diff_magnitude > 30
        
        # åˆ›å»ºæœ€ç»ˆçš„maskedå›¾åƒ
        # ç”¨æˆ·ç¼–è¾‘åçš„å›¾åƒå°±æ˜¯æˆ‘ä»¬è¦çš„æ¡ä»¶å›¾åƒ
        masked_image = edited_image.copy()
        
        # ç»Ÿè®¡maskåŒºåŸŸ
        mask_pixels = np.sum(mask_region)
        total_pixels = mask_region.size
        mask_percentage = (mask_pixels / total_pixels) * 100
        
        status = f"ç¼–è¾‘æ£€æµ‹æˆåŠŸ! MaskåŒºåŸŸ: {mask_pixels} åƒç´  ({mask_percentage:.1f}%)"
        
        return masked_image, status
        
    except Exception as e:
        return None, f"å¤„ç†ç¼–è¾‘å›¾åƒå¤±è´¥: {str(e)}"

def generate_image(prompt, num_steps, guidance_scale):
    """ç”Ÿæˆå›¾åƒçš„ä¸»å‡½æ•° - ä½¿ç”¨ç¡®è®¤çš„ç¼–è¾‘æ•°æ®"""
    global edit_confirmed, current_edit_data
    
    try:
        print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆå›¾åƒ...")
        
        # æ£€æŸ¥ç¼–è¾‘ç¡®è®¤çŠ¶æ€
        if not edit_confirmed or current_edit_data is None:
            return None, None, "âŒ è¯·å…ˆç‚¹å‡»'ç¡®è®¤ç¼–è¾‘å®Œæˆ'æŒ‰é’®"
        
        base_image = current_edit_data['base_image']
        sketch_data = current_edit_data['sketch_data']
        
        if not prompt.strip():
            return None, None, "âŒ è¯·è¾“å…¥promptæè¿°"
        
        # åˆå§‹åŒ–pipeline - å¼ºåˆ¶CUDAæ£€æŸ¥
        print("â³ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        try:
            success, init_msg = initialize_pipeline()
            if not success:
                return None, None, init_msg
            print(init_msg)
        except Exception as init_error:
            print(f"Pipelineåˆå§‹åŒ–é”™è¯¯: {init_error}")
            return None, None, f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(init_error)}"
        
        print("ğŸ–¼ï¸ ä½¿ç”¨å·²ç¡®è®¤çš„ç¼–è¾‘æ•°æ®...")
        # ç›´æ¥ä½¿ç”¨ç¡®è®¤çš„maskedå›¾åƒ
        try:
            masked_image = current_edit_data['masked_image']
            print("âœ… å·²ç¡®è®¤çš„ç¼–è¾‘æ•°æ®åŠ è½½æˆåŠŸ")
        except Exception as mask_error:
            print(f"ç¼–è¾‘æ•°æ®é”™è¯¯: {mask_error}")
            return None, None, f"âŒ ç¼–è¾‘æ•°æ®åŠ è½½å¤±è´¥: {str(mask_error)}"
        
        print("ğŸ¯ å‡†å¤‡ç”Ÿæˆæ¡ä»¶...")
        # åˆ›å»ºcondition - æ·»åŠ å®‰å…¨æ£€æŸ¥
        try:
            # ç¡®ä¿LoRAé€‚é…å™¨æ­£ç¡®åŠ è½½
            if hasattr(pipe, 'set_adapters'):
                pipe.set_adapters("sketch")
            condition = Condition(masked_image, "sketch")
        except Exception as condition_error:
            print(f"æ¡ä»¶å‡†å¤‡é”™è¯¯: {condition_error}")
            return None, None, f"âŒ æ¡ä»¶å‡†å¤‡å¤±è´¥: {str(condition_error)}"
        
        # è®¾ç½®éšæœºç§å­
        seed_everything(42)
        
        # ç”Ÿæˆå›¾åƒ - æ·»åŠ è¿›åº¦æç¤º
        print(f"ğŸš€ æ­£åœ¨ç”Ÿæˆå›¾åƒ (æ­¥æ•°: {int(num_steps)}, å¼•å¯¼å¼ºåº¦: {guidance_scale})")
        print(f"ğŸ“ Prompt: {prompt}")
        
        try:
            # ä½¿ç”¨torch.no_grad()ä¼˜åŒ–å†…å­˜ä½¿ç”¨
            with torch.no_grad():
                result = generate(
                    pipe,
                    prompt=prompt,
                    conditions=[condition],
                    height=1024,
                    width=1024,
                    num_inference_steps=int(num_steps),
                    guidance_scale=guidance_scale,
                )
            
            if result is None or len(result.images) == 0:
                return None, None, "âŒ ç”Ÿæˆå¤±è´¥ï¼šæ¨¡å‹è¿”å›ç©ºç»“æœ"
                
            result_img = result.images[0]
            print("âœ… å›¾åƒç”Ÿæˆå®Œæˆ")
            
        except Exception as gen_error:
            print(f"ç”Ÿæˆè¿‡ç¨‹é”™è¯¯: {gen_error}")
            # æ¸…ç†GPUå†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            return None, None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(gen_error)}"
        
        print("ğŸ”— æ­£åœ¨åˆ›å»ºå¯¹æ¯”å›¾...")
        # åˆ›å»ºå¯¹æ¯”å›¾åƒ - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        try:
            concat_image = Image.new("RGB", (1024 * 3, 1024))
            base_resized = base_image.resize((1024, 1024)).convert('RGB') if base_image else Image.new("RGB", (1024, 1024), (255, 255, 255))
            concat_image.paste(base_resized, (0, 0))
            concat_image.paste(masked_image, (1024, 0))
            concat_image.paste(result_img, (1024 * 2, 0))
        except Exception as concat_error:
            print(f"å¯¹æ¯”å›¾åˆ›å»ºé”™è¯¯: {concat_error}")
            # å³ä½¿å¯¹æ¯”å›¾å¤±è´¥ï¼Œä¹Ÿè¿”å›ç”Ÿæˆç»“æœ
            return result_img, None, "âš ï¸ ç”ŸæˆæˆåŠŸï¼Œä½†å¯¹æ¯”å›¾åˆ›å»ºå¤±è´¥"
        
        # ä¼˜åŒ–ä¿å­˜é€»è¾‘ - å¼‚æ­¥ä¿å­˜ï¼Œé¿å…é˜»å¡GradioçŠ¶æ€
        try:
            import threading
            
            def save_images_async():
                try:
                    os.makedirs("gradio_output", exist_ok=True)
                    result_img.save("gradio_output/result.jpg", quality=95, optimize=True)
                    concat_image.save("gradio_output/comparison.jpg", quality=95, optimize=True)
                    print("ğŸ’¾ ç»“æœå·²å¼‚æ­¥ä¿å­˜åˆ° gradio_output/")
                except Exception as save_error:
                    print(f"å¼‚æ­¥ä¿å­˜é”™è¯¯: {save_error}")
            
            # å¯åŠ¨åå°ä¿å­˜çº¿ç¨‹ï¼Œä¸é˜»å¡ä¸»æµç¨‹
            save_thread = threading.Thread(target=save_images_async, daemon=True)
            save_thread.start()
            
        except Exception as save_error:
            print(f"ä¿å­˜çº¿ç¨‹å¯åŠ¨å¤±è´¥: {save_error}")
            # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›ç»“æœ
        
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return result_img, concat_image, "ğŸ‰ ç”ŸæˆæˆåŠŸï¼"
        
    except Exception as e:
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(error_msg)
        # å‘ç”Ÿé”™è¯¯æ—¶æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        return None, None, error_msg

def update_sketch_pad(base_image):
    """å½“ä¸Šä¼ æ–°å›¾åƒæ—¶ï¼Œæ›´æ–°ç»˜åˆ¶ç”»å¸ƒçš„èƒŒæ™¯å¹¶é‡ç½®ç¼–è¾‘çŠ¶æ€"""
    global edit_confirmed, current_edit_data, last_sketch_hash
    
    # é‡ç½®ç¼–è¾‘çŠ¶æ€
    edit_confirmed = False
    current_edit_data = None
    last_sketch_hash = None
    
    if base_image is None:
        return np.ones((1024, 1024, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
    
    # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
    if isinstance(base_image, Image.Image):
        # è°ƒæ•´åˆ°1024 * 1024å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        resized_image = base_image.resize((1024, 1024)).convert('RGB')
        return np.array(resized_image)
    elif isinstance(base_image, np.ndarray):
        return base_image
    else:
        return np.ones((1024, 1024, 3), dtype=np.uint8) * 255

def check_sketch_changes(sketch_data):
    """æ£€æµ‹ç¼–è¾‘åŒºåŸŸæ˜¯å¦æœ‰å˜åŒ–ï¼Œå¹¶é‡ç½®ç¡®è®¤çŠ¶æ€"""
    global edit_confirmed, last_sketch_hash
    import hashlib
    import time
    
    if sketch_data is None:
        return "â³ ç­‰å¾…ç¼–è¾‘..."
    
    try:
        # è®¡ç®—å½“å‰ç¼–è¾‘æ•°æ®çš„å“ˆå¸Œå€¼
        if isinstance(sketch_data, dict) and 'composite' in sketch_data:
            data_to_hash = sketch_data['composite']
        else:
            data_to_hash = sketch_data
            
        if isinstance(data_to_hash, np.ndarray):
            current_hash = hashlib.md5(data_to_hash.tobytes()).hexdigest()
        else:
            current_hash = str(hash(str(data_to_hash)))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
        if last_sketch_hash != current_hash:
            if last_sketch_hash is not None:  # ä¸æ˜¯ç¬¬ä¸€æ¬¡
                edit_confirmed = False  # é‡ç½®ç¡®è®¤çŠ¶æ€
                timestamp = time.strftime("%H:%M:%S")
                print(f"ğŸ”„ [{timestamp}] æ£€æµ‹åˆ°ç¼–è¾‘å˜åŒ–ï¼Œé‡ç½®ç¡®è®¤çŠ¶æ€")
                return "ğŸ”„ æ£€æµ‹åˆ°ç¼–è¾‘å˜åŒ–ï¼Œè¯·é‡æ–°ç¡®è®¤ç¼–è¾‘"
            last_sketch_hash = current_hash
            
        if edit_confirmed:
            return "âœ… ç¼–è¾‘å·²ç¡®è®¤"
        else:
            return "â³ è¯·ç‚¹å‡»ç¡®è®¤ç¼–è¾‘æŒ‰é’®"
            
    except Exception as e:
        return f"âš ï¸ çŠ¶æ€æ£€æŸ¥é”™è¯¯: {str(e)}"

def get_current_status():
    """è·å–å½“å‰å®Œæ•´çŠ¶æ€ - ç‹¬ç«‹æŸ¥è¯¢å‡½æ•°ï¼Œä¸ä¾èµ–ç½‘ç»œåŒæ­¥"""
    global edit_confirmed, current_edit_data, last_sketch_hash, status_check_counter, last_operation_time
    import time
    
    status_check_counter += 1
    current_time = time.time()
    timestamp = time.strftime("%H:%M:%S")
    
    # å¼ºåˆ¶åˆ·æ–°çŠ¶æ€æ˜¾ç¤º
    if edit_confirmed and current_edit_data:
        hash_info = current_edit_data.get('hash', 'unknown')
        main_status = f"âœ… [{timestamp}] ç¼–è¾‘å·²ç¡®è®¤ (å“ˆå¸Œ:{hash_info}) - æ£€æŸ¥#{status_check_counter}"
        edit_status = "âœ… å·²ç¡®è®¤ï¼Œå¯ä»¥ç”Ÿæˆå›¾åƒ"
        network_status = "ğŸŸ¢ çŠ¶æ€åŒæ­¥æ­£å¸¸"
    else:
        main_status = f"â³ [{timestamp}] ç­‰å¾…ç¼–è¾‘ç¡®è®¤ - æ£€æŸ¥#{status_check_counter}"
        edit_status = "â³ è¯·å®Œæˆç¼–è¾‘å¹¶ç¡®è®¤"
        network_status = f"ğŸŸ¡ æœªç¡®è®¤çŠ¶æ€ - æ£€æŸ¥#{status_check_counter}"
    
    print(f"ğŸ“Š [{timestamp}] çŠ¶æ€æŸ¥è¯¢#{status_check_counter}: confirmed={edit_confirmed}")
    return main_status, edit_status, network_status

def backup_state():
    """å¤‡ä»½å½“å‰çŠ¶æ€åˆ°æœ¬åœ°"""
    global local_backup, edit_confirmed, current_edit_data, last_sketch_hash, last_operation_time
    import time
    
    last_operation_time = time.time()
    local_backup = {
        'edit_confirmed': edit_confirmed,
        'current_edit_data': current_edit_data,
        'last_sketch_hash': last_sketch_hash,
        'timestamp': last_operation_time
    }
    print(f"ğŸ’¾ çŠ¶æ€å·²å¤‡ä»½: confirmed={edit_confirmed}")

def restore_state():
    """ä»æœ¬åœ°å¤‡ä»½æ¢å¤çŠ¶æ€"""
    global local_backup, edit_confirmed, current_edit_data, last_sketch_hash
    import time
    
    if local_backup and time.time() - local_backup.get('timestamp', 0) < 300:  # 5åˆ†é’Ÿå†…çš„å¤‡ä»½æœ‰æ•ˆ
        edit_confirmed = local_backup.get('edit_confirmed', False)
        current_edit_data = local_backup.get('current_edit_data')
        last_sketch_hash = local_backup.get('last_sketch_hash')
        print(f"ğŸ“¥ çŠ¶æ€å·²æ¢å¤: confirmed={edit_confirmed}")
        return True
    return False

def continue_editing(base_image):
    """ç»§ç»­ç¼–è¾‘åŠŸèƒ½ - é‡ç½®æ‰€æœ‰çŠ¶æ€å¹¶è¿”å›ç¼–è¾‘æ¨¡å¼"""
    global edit_confirmed, current_edit_data, last_sketch_hash
    import time
    
    timestamp = time.strftime("%H:%M:%S")
    print(f"ğŸ”„ [{timestamp}] ç”¨æˆ·ç‚¹å‡»ç»§ç»­ç¼–è¾‘ï¼Œé‡ç½®æ‰€æœ‰çŠ¶æ€")
    
    # é‡ç½®æ‰€æœ‰ç¼–è¾‘ç›¸å…³çŠ¶æ€
    edit_confirmed = False
    current_edit_data = None
    last_sketch_hash = None
    
    # æ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # å‡†å¤‡è¿”å›ç¼–è¾‘æ¨¡å¼çš„çŠ¶æ€ä¿¡æ¯
    main_status = f"ğŸ”„ [{timestamp}] å·²é‡ç½®ï¼Œè¯·é‡æ–°ç¼–è¾‘å’Œç¡®è®¤"
    edit_status = "â³ è¯·å®Œæˆç¼–è¾‘å¹¶ç¡®è®¤"
    network_status = "ğŸŸ¢ çŠ¶æ€å·²é‡ç½®"
    
    # æ›´æ–°ç¼–è¾‘ç”»å¸ƒèƒŒæ™¯
    sketch_pad_result = update_sketch_pad(base_image)
    
    print(f"âœ… [{timestamp}] ç»§ç»­ç¼–è¾‘çŠ¶æ€é‡ç½®å®Œæˆ")
    
    return sketch_pad_result, main_status, edit_status, network_status

def confirm_edit_ready(base_image, sketch_data):
    """ç¡®è®¤ç¼–è¾‘å°±ç»ª - æç®€ç‰ˆæœ¬ï¼Œä¸“æ³¨çŠ¶æ€è®¾ç½®"""
    global edit_confirmed, current_edit_data, last_sketch_hash, last_operation_time
    
    import time
    import hashlib
    current_time = time.time()
    timestamp = time.strftime("%H:%M:%S")
    
    print(f"ğŸ”„ [{timestamp}] ===== å¼€å§‹ç¡®è®¤ç¼–è¾‘ =====")
    
    # ç«‹å³è®¾ç½®æ“ä½œæ—¶é—´
    last_operation_time = current_time
    
    # å¼ºåˆ¶é‡ç½®çŠ¶æ€ï¼Œç¡®ä¿æ¯æ¬¡éƒ½æ˜¯æ–°çš„ç¡®è®¤
    edit_confirmed = False
    current_edit_data = None
    
    # ç«‹å³åé¦ˆç”¨æˆ·æ“ä½œå·²æ”¶åˆ°
    if base_image is None:
        print(f"âŒ [{timestamp}] åŸºç¡€å›¾åƒä¸ºç©º")
        return "âŒ è¯·å…ˆä¸Šä¼ åŸºç¡€å›¾åƒ"
    
    if sketch_data is None:
        print(f"âŒ [{timestamp}] ç¼–è¾‘æ•°æ®ä¸ºç©º")
        return "âŒ è¯·å…ˆåœ¨å›¾åƒä¸Šè¿›è¡Œç¼–è¾‘"
    
    # è®¡ç®—å½“å‰ç¼–è¾‘æ•°æ®çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æµ‹å˜åŒ–
    try:
        if isinstance(sketch_data, np.ndarray):
            current_hash = hashlib.md5(sketch_data.tobytes()).hexdigest()[:8]
        else:
            current_hash = hashlib.md5(str(sketch_data).encode()).hexdigest()[:8]
        print(f"ğŸ” [{timestamp}] ç¼–è¾‘æ•°æ®å“ˆå¸Œ: {current_hash}, ä¸Šæ¬¡: {last_sketch_hash}")
    except:
        current_hash = "unknown"
    
    # æ·»åŠ æ•°æ®ç±»å‹æ£€æŸ¥
    print(f"ğŸ” [{timestamp}] æ£€æŸ¥æ•°æ®ç±»å‹ - base_image: {type(base_image)}, sketch_data: {type(sketch_data)}")
    
    try:
        # å¿«é€ŸéªŒè¯ç¼–è¾‘æ•°æ®
        print(f"â³ [{timestamp}] å¼€å§‹å¤„ç†ç¼–è¾‘æ•°æ®...")
        masked_image, status = create_masked_image_from_sketch(base_image, sketch_data)
        
        if masked_image is None:
            edit_confirmed = False
            print(f"âŒ [{timestamp}] ç¼–è¾‘æ•°æ®å¤„ç†å¤±è´¥: {status}")
            return f"âŒ ç¼–è¾‘æ•°æ®æ— æ•ˆ: {status}"
        
        # å¼ºåˆ¶æ›´æ–°çŠ¶æ€
        edit_confirmed = True
        last_sketch_hash = current_hash
        current_edit_data = {
            'base_image': base_image,
            'sketch_data': sketch_data,
            'masked_image': masked_image,
            'hash': current_hash,
            'timestamp': timestamp
        }
        
        # ç«‹å³å¤‡ä»½æˆåŠŸçŠ¶æ€
        backup_state()
        
        success_msg = f"âœ… [{timestamp}] ç¼–è¾‘å·²ç¡®è®¤ï¼(å“ˆå¸Œ:{current_hash}) {status}"
        print(f"ğŸ‰ [{timestamp}] ===== ç¡®è®¤å®Œæˆ ===== confirmed={edit_confirmed}")
        
        # è¿”å›ç®€æ´æ˜ç¡®çš„çŠ¶æ€
        return success_msg
        
    except Exception as e:
        edit_confirmed = False
        error_msg = f"âŒ [{timestamp}] ç¡®è®¤ç¼–è¾‘å¤±è´¥: {str(e)}"
        print(error_msg)
        return error_msg



# åˆ›å»ºGradioç•Œé¢
def create_ui():
    with gr.Blocks(title="OminiControl Inpainting Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ¨ OminiControl Inpainting Demo")
        gr.Markdown("**ä½¿ç”¨è¯´æ˜**: ä¸Šä¼ å›¾åƒ â†’ ç¼–è¾‘ â†’ ç¡®è®¤ â†’ ç”Ÿæˆå›¾åƒ | **å“åº”æ…¢?** ç‚¹å‡»ğŸ“ŠæŸ¥è¯¢çŠ¶æ€")
        
        # ç«–ç›´å¸ƒå±€ï¼šä¸Šä¼ å›¾åƒåŒºåŸŸ
        with gr.Row():
            base_image = gr.Image(
                label="ğŸ“¤ 1. ä¸Šä¼ åŸºç¡€å›¾åƒ",
                type="pil",
                height=512,  # å¢å¤§æ˜¾ç¤ºé«˜åº¦
                width=512
            )
        
        # ç¼–è¾‘åŒºåŸŸ
        with gr.Row():
            sketch_pad = gr.ImageEditor(
                label="ğŸ–Œï¸ 2. åœ¨åŸå›¾ä¸Šç¼–è¾‘ (ç™½ç¬”æ¶‚æŠ¹maskåŒºåŸŸï¼Œé»‘ç¬”å‹¾å‹’sketch)",
                type="numpy",
                height=600,  # æ˜¾è‘—å¢å¤§ç¼–è¾‘åŒºåŸŸ
                width=600,
                brush=gr.Brush(
                    default_size=15,
                    colors=["#FFFFFF", "#000000"],  # ç™½è‰²å’Œé»‘è‰²ç”»ç¬”
                    default_color="#FFFFFF"  # é»˜è®¤ç™½è‰²ï¼ˆç”¨äºæ¶‚æŠ¹maskï¼‰
                ),
                value=np.ones((1024, 1024, 3), dtype=np.uint8) * 255  # åˆå§‹ç™½è‰²èƒŒæ™¯
            )
        
        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ 
        with gr.Row():
            clear_btn = gr.Button("ğŸ—‘ï¸ é‡ç½®ä¸ºåŸå›¾", variant="secondary", size="sm")
            status_btn = gr.Button("ğŸ“Š æŸ¥è¯¢çŠ¶æ€", variant="primary", size="sm")
            confirm_btn = gr.Button("âœ… ç¡®è®¤ç¼–è¾‘", variant="primary", size="sm")
        
        # å‚æ•°æ§åˆ¶åŒºåŸŸ
        with gr.Row():
            with gr.Column(scale=2):
                prompt = gr.Textbox(
                    label="âœï¸ 3. è¾“å…¥Promptæè¿°",
                    placeholder="æè¿°ä½ æƒ³è¦åœ¨maskåŒºåŸŸç”Ÿæˆçš„å†…å®¹ï¼Œä¾‹å¦‚ï¼šA beautiful flower vase",
                    lines=2,
                    value="A beautiful vase"
                )
            with gr.Column(scale=1):
                num_steps = gr.Slider(
                    minimum=10,
                    maximum=50,
                    value=28,
                    step=1,
                    label="æ¨ç†æ­¥æ•°"
                )
            with gr.Column(scale=1):
                guidance_scale = gr.Slider(
                    minimum=1.0,
                    maximum=10.0,
                    value=3.5,
                    step=0.1,
                    label="å¼•å¯¼å¼ºåº¦"
                )
        
        # ç”ŸæˆæŒ‰é’®
        with gr.Row():
            generate_btn = gr.Button("ğŸš€ ç”Ÿæˆå›¾åƒ", variant="primary", size="lg")
        
        # çŠ¶æ€æ˜¾ç¤º
        with gr.Row():
            status_text = gr.Textbox(
                label="ğŸ“ çŠ¶æ€ä¿¡æ¯",
                value="è¯·ä¸Šä¼ å›¾åƒå¹¶ç»˜åˆ¶maskåŒºåŸŸ",
                interactive=False,
                lines=1
            )
        
        # ç¼–è¾‘çŠ¶æ€ç›‘æ§
        with gr.Row():
            edit_status = gr.Textbox(
                label="ğŸ¯ ç¼–è¾‘çŠ¶æ€",
                value="â³ ç­‰å¾…ç¼–è¾‘...",
                interactive=False,
                lines=1
            )
        
        # ç½‘ç»œçŠ¶æ€æ˜¾ç¤º
        with gr.Row():
            network_status = gr.Textbox(
                label="ğŸŒ ç½‘ç»œçŠ¶æ€",
                value="ğŸŸ¢ æ­£å¸¸",
                interactive=False,
                lines=1
            )
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ - æ”¹ä¸ºç«–ç›´å¸ƒå±€
        gr.Markdown("### ğŸ“Š ç»“æœå±•ç¤º")
        
        with gr.Tabs():
            with gr.TabItem("ğŸ“¸ ç”Ÿæˆç»“æœ"):
                output_image = gr.Image(
                    label="ç”Ÿæˆçš„å›¾åƒ",
                    type="pil",
                    height=600,  # å¢å¤§æ˜¾ç¤ºé«˜åº¦
                    width=600
                )
                # åœ¨ç”Ÿæˆç»“æœä¸‹æ–¹æ·»åŠ ç»§ç»­ç¼–è¾‘æŒ‰é’®
                with gr.Row():
                    continue_edit_btn = gr.Button("ğŸ”„ ç»§ç»­ç¼–è¾‘", variant="primary", size="lg")
            
            with gr.TabItem("ï¿½ å¯¹æ¯”å›¾"):
                comparison_image = gr.Image(
                    label="å¯¹æ¯”å›¾ (åŸå›¾|ç¼–è¾‘å›¾|ç”Ÿæˆç»“æœ)",
                    type="pil", 
                    height=400,  # å¯¹æ¯”å›¾ç¨å°ä¸€äº›ï¼Œå› ä¸ºæ˜¯æ¨ªå‘æ‹¼æ¥çš„
                )
        
        # ç¤ºä¾‹åŒºåŸŸ
        gr.Markdown("### ğŸ’¡ ç¤ºä¾‹")
        gr.Examples(
            examples=[
                ["assets/vase.jpg", "A crystal vase with roses"],
                ["assets/room_corner.jpg", "A modern floor lamp"],
            ],
            inputs=[base_image, prompt],
            label="ç‚¹å‡»åŠ è½½ç¤ºä¾‹"
        )
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### æ­¥éª¤è¯´æ˜:
            1. **ä¸Šä¼ å›¾åƒ**: é€‰æ‹©ä½ æƒ³è¦ç¼–è¾‘çš„åŸºç¡€å›¾åƒ
            2. **åœ¨åŸå›¾ä¸Šç¼–è¾‘**: 
               - ä½¿ç”¨**ç™½è‰²ç”»ç¬”**æ¶‚æŠ¹éœ€è¦ä¿®å¤/æ›¿æ¢çš„åŒºåŸŸï¼ˆmaskåŒºåŸŸï¼‰
               - ä½¿ç”¨**é»‘è‰²ç»†ç”»ç¬”**åœ¨maskåŒºåŸŸå†…å‹¾å‹’ä½ æƒ³è¦çš„å†…å®¹è½®å»“
            3. **ç¡®è®¤ç¼–è¾‘**: ç‚¹å‡»"âœ… ç¡®è®¤ç¼–è¾‘å®Œæˆ"æŒ‰é’®ä¿å­˜ç¼–è¾‘æ•°æ®
            4. **è¾“å…¥prompt**: è¯¦ç»†æè¿°ä½ æƒ³åœ¨ç¼–è¾‘åŒºåŸŸç”Ÿæˆçš„å†…å®¹
            5. **è°ƒæ•´å‚æ•°**: 
               - æ¨ç†æ­¥æ•°: å»ºè®®20-30ï¼Œæ›´å¤šæ­¥æ•°è´¨é‡æ›´å¥½ä½†é€Ÿåº¦æ›´æ…¢
               - å¼•å¯¼å¼ºåº¦: å»ºè®®3-5ï¼Œæ§åˆ¶ç”Ÿæˆå†…å®¹ä¸promptçš„ç›¸å…³æ€§
            6. **ç”Ÿæˆå›¾åƒ**: ç‚¹å‡»"ğŸš€ ç”Ÿæˆå›¾åƒ"æŒ‰é’®å¼€å§‹å¤„ç†
            7. **ç»§ç»­ç¼–è¾‘**: ç”Ÿæˆå®Œæˆåï¼Œç‚¹å‡»"ğŸ”„ ç»§ç»­ç¼–è¾‘"æŒ‰é’®é‡æ–°ç¼–è¾‘
            
            ### æ³¨æ„äº‹é¡¹:
            - ç¡®ä¿å·²æ­£ç¡®é…ç½®æ¨¡å‹è·¯å¾„ï¼ˆåœ¨ä»£ç ä¸­ä¿®æ”¹local_pathå’Œlora_pathï¼‰
            - å¿…é¡»å…ˆç”¨ç™½ç¬”æ¶‚æŠ¹åŒºåŸŸï¼Œå†ç”¨é»‘ç¬”å‹¾å‹’ç»†èŠ‚
            - **å¿…é¡»ç‚¹å‡»"ç¡®è®¤ç¼–è¾‘å®Œæˆ"æŒ‰é’®**æ‰èƒ½è¿›è¡Œç”Ÿæˆ
            - ç¼–è¾‘åçš„å›¾åƒï¼ˆåŒ…å«ç™½è‰²maskå’Œé»‘è‰²sketchï¼‰å°†ä½œä¸ºæ¡ä»¶å›¾è¾“å…¥æ¨¡å‹
            - å¼ºåˆ¶ä½¿ç”¨CUDAï¼Œç¡®ä¿GPUé©±åŠ¨æ­£ç¡®å®‰è£…
            
            ### ğŸš€ å“åº”æ€§é—®é¢˜è§£å†³æ–¹æ¡ˆ:
            - **ğŸ“Š æŸ¥è¯¢çŠ¶æ€**: ç‹¬ç«‹æ£€æŸ¥å½“å‰çŠ¶æ€ï¼Œä¸ä¾èµ–ç½‘ç»œåŒæ­¥
            - **âœ… ç¡®è®¤ç¼–è¾‘**: æç®€ç‰ˆç¡®è®¤ï¼Œå‡å°‘ç½‘ç»œä¾èµ–
            - **ğŸ”„ ç»§ç»­ç¼–è¾‘**: ç”Ÿæˆåé‡ç½®çŠ¶æ€ï¼Œæµç•…è¿”å›ç¼–è¾‘æ¨¡å¼
            - **å¼‚æ­¥ä¿å­˜**: å›¾ç‰‡åå°ä¿å­˜ï¼Œä¸é˜»å¡ç•Œé¢å“åº”
            
            ### ğŸ“± æŒ‰é’®ä½¿ç”¨æŒ‡å—:
            1. ç¼–è¾‘å®Œæˆå â†’ ç‚¹å‡»"âœ… ç¡®è®¤ç¼–è¾‘"
            2. å¦‚æœæ²¡ååº” â†’ ç‚¹å‡»"ğŸ“Š æŸ¥è¯¢çŠ¶æ€"æŸ¥çœ‹å½“å‰çŠ¶æ€  
            3. ç”Ÿæˆå®Œæˆå â†’ ç‚¹å‡»"ğŸ”„ ç»§ç»­ç¼–è¾‘"é‡æ–°ç¼–è¾‘
            4. è§‚å¯ŸçŠ¶æ€æ  â†’ âœ…è¡¨ç¤ºå·²ç¡®è®¤ï¼Œâ³è¡¨ç¤ºæœªç¡®è®¤
            
            ### ğŸŒ ç½‘ç»œçŠ¶æ€æŒ‡ç¤º:
            - ğŸŸ¢ ç»¿è‰²ï¼šæ­£å¸¸ | ğŸŸ¡ é»„è‰²ï¼šå»¶è¿Ÿ | ğŸ”´ çº¢è‰²ï¼šå¼‚å¸¸
            - çŠ¶æ€å®æ—¶æ›´æ–°ï¼Œæ”¯æŒæ— ç¼ç¼–è¾‘-ç”Ÿæˆ-ç»§ç»­ç¼–è¾‘å¾ªç¯
            """)
        
        # äº‹ä»¶ç»‘å®š - æ·»åŠ æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
        
        # å½“ä¸Šä¼ æ–°å›¾åƒæ—¶ï¼Œè‡ªåŠ¨æ›´æ–°ImageEditorçš„èƒŒæ™¯
        base_image.change(
            fn=update_sketch_pad,
            inputs=base_image,
            outputs=sketch_pad,
            show_progress="hidden"
        )
        
        # ç¼–è¾‘åŒºåŸŸå˜åŒ–ç›‘æ§ - æ£€æµ‹ç¼–è¾‘çŠ¶æ€å˜åŒ–ï¼Œå¸¦ç½‘ç»œçŠ¶æ€æ›´æ–°
        def check_sketch_and_network(sketch_data):
            """æ£€æŸ¥ç¼–è¾‘å˜åŒ–å’Œç½‘ç»œçŠ¶æ€"""
            sketch_status = check_sketch_changes(sketch_data)
            network_msg = check_network_status()
            return sketch_status, network_msg
        
        sketch_pad.change(
            fn=check_sketch_and_network,
            inputs=sketch_pad,
            outputs=[edit_status, network_status],
            show_progress="hidden"
        )
        
        # é‡ç½®æŒ‰é’®
        def reset_and_update_status(base_img):
            """é‡ç½®å¹¶æ›´æ–°çŠ¶æ€"""
            global edit_confirmed, current_edit_data
            edit_confirmed = False
            current_edit_data = None
            result = update_sketch_pad(base_img)
            return result, "ğŸ”„ å·²é‡ç½®ä¸ºåŸå›¾ï¼Œè¯·é‡æ–°ç¼–è¾‘"
        
        clear_btn.click(
            fn=reset_and_update_status,
            inputs=base_image,
            outputs=[sketch_pad, edit_status],
            show_progress="hidden"
        )
        
        # ç½‘ç»œçŠ¶æ€æ£€æµ‹
        def check_network_status():
            """æ£€æµ‹ç½‘ç»œçŠ¶æ€å’Œå“åº”å»¶è¿Ÿ"""
            import time
            global click_timestamps
            
            current_time = time.time()
            
            # è®¡ç®—æœ€è¿‘ç‚¹å‡»çš„å“åº”å»¶è¿Ÿ
            if len(click_timestamps) >= 2:
                avg_delay = sum(click_timestamps[-3:]) / len(click_timestamps[-3:]) - click_timestamps[-1]
                if avg_delay > 2.0:
                    return "ğŸ”´ ç½‘ç»œå»¶è¿Ÿè¾ƒé«˜ï¼Œå»ºè®®ç‚¹å‡»åˆ·æ–°æŒ‰é’®"
                elif avg_delay > 1.0:
                    return "ğŸŸ¡ ç½‘ç»œæœ‰è½»å¾®å»¶è¿Ÿ"
            
            return "ğŸŸ¢ ç½‘ç»œçŠ¶æ€æ­£å¸¸"
        # çŠ¶æ€æŸ¥è¯¢æŒ‰é’® - ç‹¬ç«‹çŠ¶æ€æ£€æŸ¥ï¼Œä¸ä¾èµ–ç½‘ç»œåŒæ­¥
        status_btn.click(
            fn=get_current_status,
            inputs=None,
            outputs=[status_text, edit_status, network_status],
            show_progress="hidden"
        )
        
        # ç¡®è®¤ç¼–è¾‘æŒ‰é’® - ç½‘ç»œå®¹é”™ç‰ˆæœ¬
        def confirm_and_update_status_with_retry(base_img, sketch_data):
            """ç¡®è®¤ç¼–è¾‘å¹¶åŒæ­¥çŠ¶æ€ - å¸¦ç½‘ç»œçŠ¶æ€æ£€æµ‹"""
            import time
            start_time = time.time()
            
            # æ‰§è¡Œç¡®è®¤æ“ä½œ
            main_status = confirm_edit_ready(base_img, sketch_data)
            
            # è®¡ç®—å“åº”æ—¶é—´
            response_time = time.time() - start_time
            
            if "âœ…" in main_status:
                edit_status_msg = "âœ… ç¼–è¾‘å·²ç¡®è®¤ï¼Œå¯ä»¥ç”Ÿæˆå›¾åƒ"
                if response_time > 3.0:
                    network_msg = "ğŸŸ¡ å“åº”è¾ƒæ…¢ï¼Œå·²å®Œæˆç¡®è®¤"
                else:
                    network_msg = "ğŸŸ¢ ç¡®è®¤æˆåŠŸï¼Œå“åº”æ­£å¸¸"
            else:
                edit_status_msg = "âŒ ç¼–è¾‘ç¡®è®¤å¤±è´¥ï¼Œè¯·é‡è¯•æˆ–ç‚¹å‡»åˆ·æ–°"
                if response_time > 5.0:
                    network_msg = "ğŸ”´ ç½‘ç»œè¶…æ—¶ï¼Œå»ºè®®ç‚¹å‡»åˆ·æ–°æŒ‰é’®"
                else:
                    network_msg = "ğŸŸ¡ ç¡®è®¤å¤±è´¥ï¼Œç½‘ç»œæ­£å¸¸"
            
            print(f"â±ï¸ ç¡®è®¤æ“ä½œå“åº”æ—¶é—´: {response_time:.2f}ç§’")
            return main_status, edit_status_msg, network_msg
        
        confirm_btn.click(
            fn=confirm_and_update_status_with_retry,
            inputs=[base_image, sketch_pad],
            outputs=[status_text, edit_status, network_status],
            show_progress="minimal"
        )
        
        # ç”ŸæˆæŒ‰é’® - å¢å¼ºçŠ¶æ€åé¦ˆå’ŒåŒæ­¥
        def safe_generate_image_with_status(prompt_text, num_steps, guidance_scale):
            """å®‰å…¨çš„ç”Ÿæˆå›¾åƒåŒ…è£…å‡½æ•°ï¼Œç¡®ä¿å§‹ç»ˆæœ‰æ˜ç¡®åé¦ˆ"""
            import time
            timestamp = time.strftime("%H:%M:%S")
            print(f"ğŸ¯ [{timestamp}] ç”ŸæˆæŒ‰é’®è¢«ç‚¹å‡»...")
            
            try:
                if not edit_confirmed:
                    error_msg = "âŒ è¯·å…ˆç‚¹å‡»'ç¡®è®¤ç¼–è¾‘å®Œæˆ'æŒ‰é’®"
                    return None, None, error_msg, "âŒ æœªç¡®è®¤ç¼–è¾‘ï¼Œæ— æ³•ç”Ÿæˆ"
                
                print(f"â³ [{timestamp}] å¼€å§‹ç”Ÿæˆå›¾åƒ...")
                result_img, comparison_img, main_status = generate_image(prompt_text, num_steps, guidance_scale)
                
                # ç”Ÿæˆå®Œæˆåçš„çŠ¶æ€
                if result_img is not None:
                    edit_status_msg = "ğŸ‰ ç”Ÿæˆå®Œæˆï¼å¦‚éœ€é‡æ–°ç¼–è¾‘è¯·ä¿®æ”¹åé‡æ–°ç¡®è®¤"
                else:
                    edit_status_msg = "âŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¼–è¾‘æ•°æ®"
                
                return result_img, comparison_img, main_status, edit_status_msg
                
            except Exception as e:
                error_msg = f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {str(e)}"
                print(f"âŒ [{timestamp}] {error_msg}")
                return None, None, error_msg, "âŒ ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸"
        
        generate_event = generate_btn.click(
            fn=safe_generate_image_with_status,
            inputs=[prompt, num_steps, guidance_scale],
            outputs=[output_image, comparison_image, status_text, edit_status],
            show_progress=True,
            scroll_to_output=True,
        )
        
        # ç»§ç»­ç¼–è¾‘æŒ‰é’® - é‡ç½®çŠ¶æ€å¹¶è¿”å›ç¼–è¾‘æ¨¡å¼
        continue_edit_btn.click(
            fn=continue_editing,
            inputs=base_image,
            outputs=[sketch_pad, status_text, edit_status, network_status],
            show_progress="hidden"
        )
        
        # é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–çŠ¶æ€
        demo.load(
            fn=get_current_status,
            inputs=None,
            outputs=[status_text, edit_status, network_status],
            show_progress="hidden"
        )
    
    return demo

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨OminiControl Inpainting Demo...")
    
    # å¼ºåˆ¶æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨ï¼ŒGPU: {torch.cuda.get_device_name()}")
    else:
        print("âŒ CUDAä¸å¯ç”¨ï¼Œç¨‹åºå°†æ— æ³•æ­£å¸¸å·¥ä½œ")
        print("ğŸ’¡ è¯·ç¡®ä¿å®‰è£…äº†æ­£ç¡®çš„GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬")
        exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("gradio_output", exist_ok=True)
    
    # å¯åŠ¨ç•Œé¢
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True,
        show_error=True
    )
